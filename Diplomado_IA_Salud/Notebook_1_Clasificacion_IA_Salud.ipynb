{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-3uvcZUt3WC0"},"outputs":[],"source":["%%html\n","<center><marquee style='width: 60%; color: blue;'><b>✌ ¡Hola a todos! Hoy es una clase importante ✌ </b></marquee><center>"]},{"cell_type":"markdown","metadata":{"id":"MmQviC6rC1ms"},"source":["<table>\n","    <tr>\n","        <td><img src=\"https://www.acofi.edu.co/eiei2016/wp-content/uploads/2016/09/Logo-Universidad-EIA.jpg\" width=\"250\"/></td>\n","        <td>&nbsp;</td>\n","        <td>\n","        <td><img src=\"https://raw.githubusercontent.com/Fabian830348/Bases_Datos/refs/heads/master/Logo_EICT_horizontal_ESPANOL%20(1).png\" width=\"300\"/></td>\n","        <td>&nbsp;</td>\n","        <td>\n","            <h1 style=\"font-size:200%;color:blue;text-align:center\">    <FONT COLOR=\"blue\"> Conceptos Machine Learning </p> Clasificación  </FONT>         </h1></td>         \n","        <td>\n","            <tp><p style=\"font-size:99%;text-align:center\">Machine Learning </p></tp>\n","            <tp><p style=\"font-size:115%;text-align:center\">Diplomado 2025-2</p></tp>\n","            <tp><p style=\"font-size:115%;text-align:center\">Prof. Fabián Sánchez</p></tp>\n","        </td>\n","    </tr>\n","</table>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Ltcxu19TC-Vx"},"source":["# <FONT SIZE=4 COLOR=\"purple\"> 1. Objetivos de la sesión: </FONT>\n","\n","✔  En esta sesión revisaremos algunos conceptos fundamentales de Machine Learning como por ejemplo, conjunto de entrenamiento, conjunto de prueba, métrica de evaluación, validación cruzada (cross-validation),  hiperparámetros, entre otros.\n","\n","✔ Por otro lado, estudiaremos en qué consisten los problemas de clasificación y estudiaremos el primer modelo clásico de este tipo: los *k-vecinos más cercanos*. Además, revisaremos la matriz de confusión y las diferentes métricas como el *recall* , *accuracy*, *precision*, etc.\n"]},{"cell_type":"markdown","metadata":{"id":"M0hu572uGmEi"},"source":["# <FONT SIZE=4 COLOR=\"purple\"> 2. Conceptos básicos de Machine Learning </FONT>\n","\n","En está sección revisaremos algunos conceptos básicos de machine learning.\n","\n","<FONT SIZE=3 COLOR=\"green\"> a. Algoritmos de clasificación: </FONT>  técnicas de aprendizaje supervisado para hacer predicciones sobre una variable objetivo $\\mathbf{y}$ que es categórica o discreta con pocos valores.\n","\n","\n","<center><FONT SIZE=4 COLOR=\"BLUE\">Situación 1 </FONT></center>\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/d6bb35cb0a6e29c3995fa8a88c83ec24cf2bc6e8/SVM/svm5.png?raw=true\" alt=\"centered image\" width=\"700\" height=\"300\"></center> <center><figcaption> <FONT SIZE=1 COLOR=\"black\"> Fuente: Elaboración propia  </FONT> <figcaption></center>\n","<br>\n","\n","<center><FONT SIZE=4 COLOR=\"BLUE\">Situación 2 </FONT></center>\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/d6bb35cb0a6e29c3995fa8a88c83ec24cf2bc6e8/SVM/svm6.png?raw=true\" alt=\"centered image\" width=\"700\" height=\"300\"></center> <center><figcaption> <FONT SIZE=1 COLOR=\"black\"> Fuente: Elaboración propia  </FONT> <figcaption></center>\n","<br>\n","\n","<FONT SIZE=3 COLOR=\"green\"> b. Variable Objetivo: </FONT> también denominada **variable de respuesta**. En un algoritmo de aprendizaje de máquina supervisado, es la variable que queremos predecir (por lo general, denotada como $\\mathbf{y}$). Esta puede ser discreta o continua. En el primer caso, da lugar a algoritmos de ***clasificación*** y en el segundo caso a algoritmos de ***regresión***.\n","\n","<br>\n","\n","<FONT SIZE=3 COLOR=\"green\"> c. Variable(s) Predictora(s): </FONT> también denominada ***features*** o características, son las variables que se usarán para predecir la variable objetivo. Estas se denotan como\n","\n","$$\\mathbf{X}=\\{X_1,X_2, \\dots, X_n \\}$$\n","\n","<br>\n","\n","<FONT SIZE=3 COLOR=\"green\"> d. Conjunto de Entrenamiento: </FONT> es el subconjunto de registros que se selecciona para entrenar el modelo. Este conjunto consta de dos partes:\n","\n","- $X_{train}$ : conjunto de entrenamiento de los predictores o *features*.\n","\n","- $y_{train}$: conjunto de entrenamiento de la variable objetivo asociada al conjunto $X_{train}$.\n","\n","El conjunto de entrenamiento se selecciona de manera aleatoria y por lo general se toma el $70\\%$ , $75\\%$ y $80 \\%$.\n","\n","<br>\n","\n","<FONT SIZE=3 COLOR=\"green\"> e. Conjunto de Prueba: </FONT>: Es el subconjunto de registros que se selecciona para validar el modelo. Consta de dos partes:\n","\n","- $X_{test}$ : conjunto de validación de los predictores o *features*.\n","\n","- $y_{test}$: conjunto de validación de la variable objetivo asociada al conjunto $X_{test}$.\n","\n","El tamaño de este conjunto es el complemento del conjunto de entrenamiento.\n","\n","**Nota:** para algoritmos clásicos de machine learning se acostumbra dividir en entrenamiento y prueba. Sin embargo, en algoritmos más complejos que requieren el entrenamiento de mucho parámetros, como es el caso de las redes neuronales, se acostumbra dividir en tres partes: *train* , *validation* and *test*.\n","\n","<center><FONT SIZE=4 COLOR=\"BLUE\"> ESQUEMA GENERAL DE CLASIFICACIÓN EN MACHINE LEARNING </FONT></center>\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Intro-knn/ESQUEMA%20DE%20CLASIFICACI%C3%93N.png?raw=true\" alt=\"centered image\" width=\"700\" height=\"400\"></center> <center><figcaption> <FONT SIZE=1 COLOR=\"black\"> Fuente: Elaboración propia  </FONT> <figcaption></center>\n","<br>\n","\n","<br>\n","\n","<FONT SIZE=3 COLOR=\"green\"> f. Matriz de Confusión:</FONT> Herramienta usada para evaluar el rendimiento del modelo. (se ampliará más adelante las métricas y conceptos).\n","\n","<br>\n","\n","<FONT SIZE=3 COLOR=\"green\"> g. Hiperparámetro: </FONT> son variables de configuración externa al modelo original (general) que se pueden ajustar para entrenar el modelo. (cada modelo tiene diferentes hiperparámetros)"]},{"cell_type":"markdown","metadata":{"id":"AYn5w5oBqtzP"},"source":["A continuación, revisaremos en detalle uno de los primeros algoritmos de machine learning y con este ilustraremos algunos conceptos y herramientas que aplican también para otros algoritmos de clasificación."]},{"cell_type":"markdown","metadata":{"id":"0TnsrU_7kbgR"},"source":["# <FONT SIZE=4 COLOR=\"Purple\"> 3. Algoritmo de clasificación KNN : K-vecinos más cercanos </FONT>\n","\n","En esta sección revisaremos el algoritmo de clasificación ***KNN: k-nearest neighbors*** : K-vecinos más cercanos."]},{"cell_type":"markdown","metadata":{"id":"z6UUUh63lb0P"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 3.1 ¿En qué consiste? </FONT>\n","\n","Este algoritmo consiste en clasificar los valores de una variable categórica de acuerdo con los vecinos más cercanos. A continuación explicaremos el funcionamiento"]},{"cell_type":"markdown","metadata":{"id":"vcCknbLpmz51"},"source":["1. Supongamos que queremos clasificar el cuadrado amarillo en las dos posibles clases.\n","\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Intro-knn/knn1.png?raw=true?\" alt=\"centered image\" width=\"600\" height=\"450\"></center> <center><figcaption> <FONT SIZE=1 COLOR=\"black\"> Fuente: Libro Guía  </FONT> <figcaption></center>\n","\n","\n"]},{"cell_type":"markdown","source":["La decisión se toma por la clase mayoritaria que hay en la vecindad."],"metadata":{"id":"T_zRwPbQkx_Q"}},{"cell_type":"markdown","metadata":{"id":"Rr63K3NRoDx9"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 3.2 Descripción del algoritmo: pseudocódigo </FONT>\n","\n","- Determinar el valor de $k$.\n","\n","- Calcular la distancia del punto a clasificar a todos los otros puntos.\n","\n","- Ordenar de manera ascendente las distancias.\n","\n","- Tomar los puntos más cercanos al punto a clasificar de acuerdo con el valor que le asignemos a $k$.\n","\n","- Contar cuántos puntos de cada clase están en la vecindad y definimos por mayoría.\n","\n","- Por ejemplo: Si $k$ es 3 y tenemos\n","\n","   + Distancia 1 : 2.5 : clase a\n","\n","   + Distancia 2 : 2.51 : clase b\n","\n","   + Distancia 3 : 2.53 : clase a\n","\n","  Conclusión: El punto se clasifica en la clase a.\n","\n","En caso de que haya empate se pueden definir algunos criterios de desempate. Por ejemplo:\n","\n","  - la clase que contenga al vecino más cercano.\n","  - la clase con la distancia media más pequeña."]},{"cell_type":"markdown","metadata":{"id":"Wa22mH3xnPJf"},"source":["Con base al funcionamiento delñ algoritmo de *kNN* podemos observar que es sennsible al valor asignado a $k$.\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Intro-knn/knn2.png?raw=true?\" alt=\"centered image\" width=\"600\" height=\"450\"></center> <center><figcaption> <FONT SIZE=1 COLOR=\"black\"> Fuente: Libro Guía  </FONT> <figcaption></center>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"uJOahxNMW7mZ"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 3.3 Sobre el algoritmo </FONT>\n","\n","A continuación, algunos puntos importantes que se deben tener en cuenta sobre el algoritmo ***knn***\n","\n","1. Observe que no se genera un modelo que sea consecuencia de un entrenamiento previo, sino que el aprendizaje se da en el mismo momento en el que se prueban los datos de validación. A este tipo de algoritmos se les denomina ***lazy learning methods***.\n","\n","2. Como utiliza todo el set de entrenamiento para calcular las distancias, se tiene un costo computacional alto.\n","\n","3. Es un algoritmo que da buenos resultados, pero es recomendable para conjuntos de datos no tan grandes.\n","\n","4. Es muy sensible al valor de $k$ y a la distancia seleccionada.\n","\n","5. Es importante escalar los datos."]},{"cell_type":"markdown","metadata":{"id":"E2oMMh1Goqyr"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 3.4 Sobre las distancias </FONT>\n","\n","El algoritmo $knn$ está fundamentado en la distancia entre dos puntos. Si bien, una de las distancias más conocida es la distancia euclideana, existen otras distancias que se pueden usar para el algoritmo.\n","\n","## <FONT SIZE=3 COLOR=\"magenta\"> Distancia Euclideana </FONT>\n","\n","$$ \\left (\\sum \\limits_{i=1}^n (x_i-y_i)^2 \\right)^{1/2}$$\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Intro-knn/dis_euclide.png?raw=true\" alt=\"centered image\" width=\"600\" height=\"300\"></center> <center><figcaption> <FONT SIZE=1 COLOR=\"black\"> Fuente: Elaboración propia  </FONT> <figcaption></center>\n","<br>\n","\n","Esta métrica se puede usar para variables con valores discretos o continuos en general.\n","\n","## <FONT SIZE=3 COLOR=\"magenta\"> Distancia de Manhattan</FONT>\n","\n","$$ \\sum \\limits_{i=1}^{n} |x_i-y_i|$$\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Intro-knn/dis_manhattan.png?raw=true\" alt=\"centered image\" width=\"600\" height=\"300\"></center> <center><figcaption> <FONT SIZE=1 COLOR=\"black\"> Fuente: Elaboración propia  </FONT> <figcaption></center>\n","<br>\n","\n","Observe que es más sencilla que la euclideana (tiene menos cálculos)\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Intro-knn/knn3.png?raw=true?\" alt=\"centered image\" width=\"600\" height=\"450\"></center> <center><figcaption> <FONT SIZE=1 COLOR=\"black\"> Fuente: Elaboración propia  </FONT> <figcaption></center>\n","\n","La métrica euclideana y de Manhattan tienen una generalización que se denomina.\n","\n","## <FONT SIZE=3 COLOR=\"magenta\"> Distancia de Minkowski</FONT>\n","\n","$$ \\left (\\sum \\limits_{i=1}^n |x_i-y_i|^p \\right)^{1/p}$$\n","\n","## <FONT SIZE=3 COLOR=\"magenta\"> Distancia de Hamming</FONT>\n","\n","$$Distancia \\,\\, Hamming : \\begin{cases} 0 & \\text{si $x=y$} \\\\ 1 & \\text{si $x \\neq y$}   \\end{cases}$$\n","\n","Esta distancia es equivalente a la de Manhattan para variables binarias, es decir, que solo tienen ceros y unos\n","\n","$$ a = \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 1 \\end{pmatrix}  \\qquad b = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$$\n","\n","## <FONT SIZE=3 COLOR=\"magenta\"> Distancia Euclideana con pesos </FONT>\n","\n","$$ \\left (\\sum \\limits_{i=1}^n w_i(x_i-y_i)^2 \\right)^{1/2}$$\n","\n","donde los pesos resultan, por ejemplo, del escalamiento de los datos.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Lypilljgelwo"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 3.5 Sobre los valores de $k$ </FONT>\n","\n","Un parámetro muy importante en el algoritmo de *knn* es el valor de $k$.  Inicialmente, no hay una forma general de escogerlo, sin embargo\n","\n","- Si se toma un valor de $k$ muy pequeño se puede sobreajustar (overfitting).\n","\n","- Si el valor de $k$ es muy grande sucede lo contrario. Será más dificil clasificar.\n","\n","- En clasificación binaria se recomienda tomar $k$ impar para evitar empates. Iniciar con $k= 5,7,9 \\dots$\n","\n","- Un valor inicial que se puede tomar es $k=\\sqrt{n}$, donde $n$ es el número de datos y a partir de este se ajusta el modelo.\n","\n","- Se recomienda **Tunear** (optimizar) el hiperparámetro $k$. Se dice hiperparámetro ya que es un parámetro que se utiliza para entrenar el modelo."]},{"cell_type":"markdown","metadata":{"id":"yKuq0-jjgcgl"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 3.6 Sobre el escalamiento </FONT>\n","\n","El algoritmo *knn* está fundamentado en seleccionar mínimas distancias, en ese orden de ideas, observe lo siguiente.\n","\n","- Si se tiene una variable $X_1$ que varía en $[1,2]$ y otra variable $X_2$ que varía en $[1000, 2000]$. Al calcular distancias con los valores de estas variables $X_2$ dominará a $X_1$ que tiene valores más pequeños y como el algoritmo utiliza la distancia para clasificar entonces queda sesgado el resultado.\n","\n","Por lo anterior, se deben escalar las variables predictoras y en general se usan las siguientes dos funciones.\n","\n","## <FONT SIZE=3 COLOR=\"blue\"> StandardScaler </FONT>\n","\n","$$\\dfrac{X-\\mu}{\\sigma}$$\n","\n","Se denomina estandarización\n","\n","## <FONT SIZE=3 COLOR=\"blue\"> MaxminScaler </FONT>\n","\n","$$\\dfrac{X-X_{min}}{X_{max}-X_{min}}$$\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dmBWtchOkxMQ"},"source":["A continuación, revisaremos un ejemplo donde ilustraremos los conceptos, el código de programación y otros elementos importantes."]},{"cell_type":"markdown","metadata":{"id":"jU2O_Ocdk-MD"},"source":["# <FONT SIZE=5 COLOR=\"purple\"> 4. Ejemplo Práctico </FONT>\n","\n","- En esta sección haremos un ejemplo práctico.\n","\n","- Iniciaremos indicando las librerías que debemos usar."]},{"cell_type":"markdown","metadata":{"id":"LQk9kTV1lZw0"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 4.1 Librerías de trabajo </FONT>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fmJaik-Alf_S"},"outputs":[],"source":["# Manipulación de data.frames\n","import pandas       as pd\n","import numpy        as np\n","\n","# Librerías para Gráficos\n","import matplotlib.pyplot  as plt\n","import seaborn            as sns\n","import plotly.express     as px\n","\n","# Librerías para datos de entrenamiento y prueba\n","from sklearn.model_selection    import train_test_split\n","\n","# Para preprocesamiento/escalar los datos\n","from sklearn.preprocessing      import StandardScaler, MinMaxScaler\n","\n","# Para aplicar k-nearest neighbors\n","from sklearn.neighbors          import KNeighborsClassifier\n","from sklearn.linear_model       import LogisticRegression\n","from sklearn.tree               import DecisionTreeClassifier\n","\n","# Métricas de evaluación\n","from sklearn                    import metrics\n","from sklearn.metrics            import confusion_matrix, ConfusionMatrixDisplay, classification_report\n","from sklearn.metrics            import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score\n","from imblearn.metrics           import specificity_score\n","\n","# Optimización de hiperparámetros\n","from sklearn.model_selection    import GridSearchCV\n","\n","# Para ignorar los warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"HkINXW4WmU5O"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 4.2 Contexto del problema </FONT>\n","\n","En este caso, veremos un caso típico de problema de clasificación. Queremos predecir si una integrante de una muestra que representa a una población, tiene diabetes. Queremos hacer esto a partir de múltiples variables que tenemos de cada una de las pacientes:\n","\n","- ***Pregnancies***: Número de embarazos que ha tenido en su vida\n","- ***Glucose***: Nivel de concentración de glucosa en sangre\n","- ***BloodPressure***: Presión arterial\n","- ***SkinThikness***: Espesor de piel a la altura del triceps\n","- ***Insulin***: Respuesta a dosis de insulina en 2 horas\n","- ***BMI***: Índice de masa corporal\n","- ***DiabetesPedigreeFunction***: Presencia de diabetes en ascendencia directa\n","- ***Age***: Edad del paciente\n","- ***Outcome***: Variable que queremos predecir:\n","   - $1$ : Tiene diabetes\n","   - $0$ : No tiene diabetes\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gvKTG0D5pHv9"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 4.3 Importar los datos </FONT>\n","\n","Lo primero que haremos es importar los datos que están en el siguiente link o pueden ser descargados de la página de Kaggle.\n","\n","https://raw.githubusercontent.com/Fabian830348/Bases_Datos/master/diabetes.csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gPKIEFqGqDJn"},"outputs":[],"source":["url = \"https://raw.githubusercontent.com/Fabian830348/Bases_Datos/master/diabetes.csv\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TCkook-pqDG3"},"outputs":[],"source":["diabetes= pd.read_csv(url)"]},{"cell_type":"code","source":["diabetes.head()"],"metadata":{"id":"Y_2sExAnAvom"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wlgRkB50rYvW"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 4.4 Exploración rápida de los datos </FONT>\n","\n","Antes de hacer cualquier modelo de machine learning o análisis similar es fundamental entender y explorar las variables del conjunto de datos."]},{"cell_type":"code","source":["# cabeza de los datos (primeros)\n"],"metadata":{"id":"_HxOsJo6xx5r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# cola de los datos (último registros)\n"],"metadata":{"id":"ejhGdo4Sx0GV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# revisar las columnas de los datos\n"],"metadata":{"id":"74vN4faAyJZ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tamaño de los datos\n"],"metadata":{"id":"f9ZBxTjNQCO6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# revisar la información de los datos\n"],"metadata":{"id":"CUzSNjbMyMtu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# estadísticos descriptivos\n"],"metadata":{"id":"WxO1qrUVySvy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora, vamos a hacer dos pasos adicionales de alistamiento del conjunto de datos:\n","\n","1. vamos a cambiar el nombre de la variable Outcome por Resultado\n","\n","2. Vamos a explorar la variable objetivo"],"metadata":{"id":"OQWqFO-EyXzB"}},{"cell_type":"code","source":["diabetes.head()"],"metadata":{"id":"5czon2XUS_ps"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# cambiar el nombre de la variable objetivo\n","# inplace : sobreescribir o no\n","diabetes.rename(columns = {\"Outcome\" : \"resultado\"}, inplace = True)"],"metadata":{"id":"Q5S8E607yjAB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["diabetes.head()"],"metadata":{"id":"Z6dp-Omzy88E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vamos a revisar la variable objetivo"],"metadata":{"id":"rJsJZtUDRzQ_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"uoFRd8uMqTNB"},"outputs":[],"source":["# contar las categorias de la variable resultado\n","diabetes.resultado.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"hS0mIidmxVYL"},"source":["Hacemos la gráfica de barras de las frecuencias"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JqTnwtMuqdXB"},"outputs":[],"source":["# gráfica con plotly express\n","px.bar(diabetes.resultado.value_counts(),\n","       color = [\"no\", \"si\"])"]},{"cell_type":"code","source":["px.pie(diabetes,\n","       names = \"resultado\" )"],"metadata":{"id":"ZFw8uf_v38y7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rDxGEnEswVeV"},"source":["**Cuidado 🍳**: En esta parte hay que tener especial atención,  particularmente en otros algoritmos. Cuando los datos están desbalanceados pueden afectar los resultados. Para esto se puede usar algunas técnicas de balanceo de datos: *subsampling*, *oversampling* y *smote*.\n","\n","- Para continuar con el ejercicio, trabajaremos con las clases como están."]},{"cell_type":"markdown","source":["Otras gráficas"],"metadata":{"id":"ohFf6g94uuJl"}},{"cell_type":"code","source":["# tabla de frecuencias de la variable *pregnancies*\n","diabetes.Pregnancies.value_counts()"],"metadata":{"id":"8Ux8W-cAu82q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# gráfico de barras de la variable *Pregnancies*\n","px.bar(diabetes.Pregnancies.value_counts())"],"metadata":{"id":"az99CZJ5vVBo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Podemos observar que la concentración de registros están en pacientes de 0,1 y 2 embarazos."],"metadata":{"id":"aQHJd8WEx0jN"}},{"cell_type":"code","source":["# boxplot de la variable edad\n","px.box(diabetes,\n","       y = \"Age\")"],"metadata":{"id":"r80VbACFuvtI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["De acuerdo con la gráfica anterior no hay datos atípicos por debajo del límite inferior. Por encima se presentan, algunos datos atípicos."],"metadata":{"id":"s6XOA5Lix8Nu"}},{"cell_type":"code","source":["# boxplot de la variable edad vs resultado\n","px.box(diabetes,\n","       y = \"Age\",\n","       x = \"resultado\",\n","       color = diabetes.resultado)"],"metadata":{"id":"fWk5FXVVxW23"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Se observa que en los pacientes con diabetes son mayores que los pacientes sin diabetes. Sin embargo hay algunas personas mayores que no tienen diabetes."],"metadata":{"id":"z_EWkLbCyHXz"}},{"cell_type":"code","source":["# histograma de la variable glucosa\n","px.histogram(diabetes,\n","             x = \"Glucose\")"],"metadata":{"id":"zQqyA00Hwea9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Se deja al lector que continue explorando más gráficas"],"metadata":{"id":"lW2pvIyexugz"}},{"cell_type":"markdown","metadata":{"id":"iod7SswDw-a3"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 4.5 Conjunto de Entrenamiento y Prueba </FONT>\n","\n","- **data training:** Datos que usamos para entrenar el modelo.\n","\n","- **testing data:** Datos que reservamos para comprobar si el modelo generado a partir de los datos de entrenamiento, funciona\n","\n","Normalmente, usamos $70\\%-30\\%$ / $80\\%-20\\%$"]},{"cell_type":"code","source":["diabetes.head()"],"metadata":{"id":"wKcifH2uAU_y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Primero le daremos nombre a la variable objetivo ($y$) y a las variables predictoras ($X$)."],"metadata":{"id":"3JuC3tLLzJBw"}},{"cell_type":"code","source":["diabetes.head()"],"metadata":{"id":"8trYhJp9xfde"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# la variable objetivo\n","y = diabetes[\"resultado\"]\n","# las variables predictoras\n","X = diabetes.drop(\"resultado\", axis=1)"],"metadata":{"id":"RC3VkBQmzP_A"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nueOG15Tqsfd"},"outputs":[],"source":["# Dividir en dos conjuntos: entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X,                        # variables predictoras\n","                                                    y,                        # variable de respuesta\n","                                                    stratify = y,             # garantiza que los resultados se distribuyan igual\n","                                                    random_state = 0,         # semilla para que al ejecutar siempre de igual\n","                                                    test_size = 0.3)          # tamaño del conjunto de prueba (también se puede train)"]},{"cell_type":"markdown","metadata":{"id":"q1LiaIp50Y2L"},"source":["Veamos los tamaños de estos conjuntos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pJRMrfwi0e_g"},"outputs":[],"source":["print(\"El tamaño del conjunto de datos {}\".format(diabetes.shape))\n","print(\"El tamaño de X_train es {}\".format(X_train.shape))\n","print(\"El tamaño de y_train es: {}\".format(y_train.shape))\n","print(\"El tamaño de X_test es {}\".format(X_test.shape))\n","print(\"El tamaño de y_test es: {}\".format(y_test.shape))"]},{"cell_type":"markdown","metadata":{"id":"b9nM26Ic0cQc"},"source":["Exploremos alguno de ellos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5W4WbOA5JAJe"},"outputs":[],"source":["# los primeros datos del conjunto de entrenamiento\n","X_train.head()"]},{"cell_type":"code","source":["# los primeros datos del conjunto de prueba\n","y_train.head()"],"metadata":{"id":"M8lye22V3FwZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_IvjR_fr0mBP"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 4.6 Escalar las variables predictoras </FONT>\n","\n","- En los algoritmos donde se vea involucrada una distancia es importante hacer el escalamiento.\n","\n","- Una recomendación es hacer el escalamiento después de dividir en entrenamiento y prueba, ya que la idea es evitar el **data leakage** o fuga de datos.Esto es, cuando información del conjunto de prueba (test) se filtra hacia el conjunto de entrenamiento, haciendo que el modelo aprenda de datos que no debería conocer.\n","\n","- En este caso vamos a escalar todas las variables ya que son numéricas. Sin embargo, si el conjunto de variables predictoras contiene variables catagóricas se recomienda no escalarla, ya que no son numéricas. En un próximo ejemplo se revisara esta situación.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NXOutoIs1CcK"},"outputs":[],"source":["# definimos la función para escalar\n","escalar = StandardScaler()\n","# lo aplicamos a los conjuntos\n","X_train_s = escalar.fit_transform(X_train)\n","X_test_s = escalar.transform(X_test)"]},{"cell_type":"code","source":["X_train_s"],"metadata":{"id":"PDsNWYanekKu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aJncrGo-1F_R"},"source":["**Observación importante de lo anterior**.\n","\n","a. Para $X_{train}$ usamos ***fit.transform*** esto significa que los datos de este conjunto se escalarán con base a su $\\mu$ media y $\\sigma$ desviación estándar. (que no son lo mismo que calcularla sobre todo el conjunto)\n","\n","b. Para $X_{test}$ usamos ***.transform*** esto significa que para escalar los datos del conjunto de prueba se usan los parámetros $\\mu$ y $\\sigma$ obtenidos en la parte a. con el conjunto de entrenamiento $X_{train.}$\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Intro-knn/knn4.png?raw=true?\" alt=\"centered image\" width=\"600\" height=\"400\"></center> <center><figcaption> <FONT SIZE=1 COLOR=\"black\"> Fuente: Elaboración propia  </FONT> <figcaption></center>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ImKRyOLx2vVs"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 4.7 Selección de $k$  </FONT>\n","\n","- Inicialmente seleccionamos un valor un $k$, entrenamos el modelo y luego revisamos otros valores de $k$ para ver si tenemos mejores resultados."]},{"cell_type":"markdown","metadata":{"id":"j904Yynv3D7C"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 4.8 Generar el Modelo  </FONT>\n","\n","En esta parte usaremos la librería *sciki-learn* y la función *KNeighborsClassifier*.\n","\n","Para generar el modelo tenemos múltiples alternativas, ya que podemos seleccionar:\n","\n","   - **k** : número de vecinos. Por defecto $k=5$\n","   - La **métrica** : *manhattan* , *euclidean*, etc.\n","   - Los pesos **weights**: *uniform* y *distance*. Por defecto *uniform*\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EVHP8iWx3GKI"},"outputs":[],"source":["# definir el modelo\n","KNN = KNeighborsClassifier(n_neighbors = 10,         # número de vecinos k=10\n","                           metric = 'euclidean',     # métrica euclideana\n","                           weights= \"uniform\")       # peso que se asigna a los datos"]},{"cell_type":"code","source":["# entrenar el modelo\n","KNN.fit(X_train_s,y_train)"],"metadata":{"id":"mo0als2agPYA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vamos a evaluar qué tan bien está haciendo la clasificación el modelo"],"metadata":{"id":"-bvrrKPA3vQS"}},{"cell_type":"markdown","metadata":{"id":"PsoZTQB33j66"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 4.9 Evaluar en el conjunto de Prueba  </FONT>\n","\n","Luego de tener el modelo entrenado con $X_{train}$ y $y_{train}$ pasamos a calcularlo en el conjunto $X_{test}$, con lo cual obtendremos valores de predicción del modelo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y3LZQ9s63n1U"},"outputs":[],"source":["# se utiliza la función .predict\n","y_pred = KNN.predict(X_test_s)\n","y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U__P1T43EgT_"},"outputs":[],"source":["# estos son los valores reales.\n","np.array(y_test)"]},{"cell_type":"markdown","metadata":{"id":"3Gzcmncd7CRx"},"source":["La pregunta que nos hacemos ahora es:\n","\n","***¿Qué tanta coincidencia hay en el modelo con los datos de prueba?***\n","\n","La respuesta a esta pregunta la tendremos justamente comparando **$y_{pred}$** con **$y_{test}$**. Esto lo haremos con una herramienta muy importante en Machine Learning y modelos de clasificación denominada ***matriz de confusión***."]},{"cell_type":"markdown","metadata":{"id":"k36weu033utG"},"source":["# <FONT SIZE=5 COLOR=\"purple\"> 5. Matriz de Confusión </FONT>\n","\n","En el campo del Machine Learning la **matriz de confusión** es una herramienta que permite visualizar el desempeño de un algoritmo de clasificación.\n","\n","- Las columnas de la matriz representa el número de predicciones de cada clase.\n","\n","- Las filas representan las instancias en la clase real.\n","\n","Esta matriz permite ver qué tipos de aciertos y errores está teniendo nuestro modelo a la hora de pasar por el proceso de aprendizaje con los datos.\n","\n","En el siguiente gráfico se muestra lo anterior\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Imagen/metricas.png?raw=true\" alt=\"centered image\" width=\"500\" height=\"400\"></center>\n","<br>\n","\n","Para entender la matriz de confusión veamos algunas definiciones:\n","\n","**Verdadero positivo:** El valor real es positivo y la prueba predice también que es positivo.\n","\n","- La persona estaba enferma y el modelo predice bien que estaba enferma. *Predicción correcta*\n","\n","**Verdadero negativo:** El valor real es negativo y la prueba predice también que el resultado es negativo.\n","\n","- La persona no está enferma y el modelo predice que no está enferma. *Predicción correcta*\n","\n","**Falso negativo:** El valor real es positivo, y la prueba predice que el resultado es negativo.\n","\n","- La persona esta enferma y el modelo predice que no lo está. *predicción incorrecta* : error tipo II\n","\n","**Falso positivo:** El valor real es negativo, y la prueba predice que el resultado es positivo.\n","\n","- La persona no está enferma y el modelo predice que lo está. *predicción incorrecta* : error tipo I\n","\n","Veamos las métricas que se utilizan para evaluar el modelo.\n","\n","\n"]},{"cell_type":"markdown","source":["## <FONT SIZE=5 COLOR=\"green\"> 5.1 Métricas Utilizadas para evaluar un modelo </FONT>\n","\n","<FONT SIZE=5 COLOR=\"blue\"> 1. Accuracy (exactitud) </FONT>\n","\n","- Es el porcentaje de predicciones correctas de todo el modelo.\n","\n","- Es la proporción de resultados verdaderos (tanto verdaderos positivos (VP) como verdaderos negativos (VN)) dividido entre el número total de casos examinados (verdaderos positivos, falsos positivos, verdaderos negativos, falsos negativos)\n","\n","$$Accurary = \\dfrac{VP+VN}{VP+FN+VN+FP}$$\n","\n","Observación: Si los datos están desbalanceados se debe revisar con cuidado, ya que el rendimiento general puede ser alto, pero en una de las categorias o clases no se evidencian buenos resultados. Veamos el siguiente ejemplo\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Imagen/confusión_ej1.PNG?raw=true\" alt=\"centered image\" width=\"600\" height=\"400\"></center>\n","<br>\n","\n","- Se está detectando *spam* y el rendimiento del modelo es $94\\%$. Sin embargo, el *recall* es de solo el $16\\%$ que es la clase que quiero detectar\n","\n","<FONT SIZE=5 COLOR=\"blue\"> 2. Recall (sensibilidad) </FONT>\n","\n","Es el porcentaje de los casos positivos reales que fueron detectados correctamente por el modelo. Es decir es la tasa de verdaderos positivos o **True Positive Rate (TPR)**.\n","\n","$$recall = \\dfrac{VP}{VP+FN}$$\n","\n","- *En el área de la salud se dice que la sensibilidad o recall es la capacidad de de poder detectar correctamente la enfermedad entre los enfermos*\n","\n","\n","- El *recall* prioriza la detección de los casos positivos. Es conveniente usarlo cuando los falsos negativos resultan costosos para el contexto.\n","\n","- **Observaciones**: ¿Cuándo usar esta métrica?\n","   \n","- Se usa si los falsos negativos son inaceptables en el contexto.\n","\n","   - **Diagnóstico médico:** Mejor detectar a más pacientes enfermos, aunque haya falsos positivos.\n","\n","   - **Sistemas de seguridad:** Mejor marcar posibles amenazas, aunque algunas sean erróneas.\n","\n","   - **Reconocimiento facial en aeropuertos:** Detectar terroristas aunque algunos pasajeros inocentes sean revisados.\n","\n","- No se usa si los falsos positivos dan problema en el contexto.\n","\n","   - **Detección de fraude:** No se puede marcar muchas transacciones legítimas como fraude.\n","\n","   - **Clasificación de correos spam:** No queremos que correos importantes terminen en spam.\n","\n","<FONT SIZE=5 COLOR=\"blue\"> 3. Precision (Precisión) </FONT>\n","\n","- Es la proporción de verdaderos positivos dividido entre los resultados etiquetados como positivos.\n","\n","- Indica qué tan confiables son las predicciones positivas de un modelo de clasificación. Muy útil cuando los Falsos Positivos (FP) son costosos y se quiere evitar predicciones incorrectas de la clase positiva.\n","\n","$$Precision = \\dfrac{VP}{VP+FP}$$\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Imagen/confusión_ej2.PNG?raw=true\" alt=\"centered image\" width=\"600\" height=\"400\"></center>\n","<br>\n","\n","- Esta métrica no funciona bien si los datos están desbalanceados.\n","\n","- No es útil si los falsos negativos (FN) son más graves que los falsos positivos. Por ejemplo, en detección de terremotos, es preferible dar muchas alertas (FP) antes que ignorar un sismo real (FN).\n","\n","<FONT SIZE=5 COLOR=\"blue\"> 4. Especifity (Especificidad) </FONT>\n","\n","- Es la proporción de casos negativos que fueron correctamente identificadas por el algoritmo. Es decir, es la tasa de  Verdaderos Negativos.\n","\n","$$Especifity = \\dfrac{VN}{VN+FP}$$\n","\n","*En el area de la salud se dice que la especificidad es la capacidad de poder identificar los casos de pacientes sanos entre todos los sanos*\n","\n","- **Ventajas de la Especificidad**\n","\n","   - Minimiza los falsos positivos (FP). Es clave cuando un falso positivo tiene consecuencias graves, como una sanción injusta. Por ejemplo, en la detección de terrorismo, se queremos marcar inocentes como sospechosos.\n","   - Ideal en sistemas donde una decisión errónea tiene altos costo Por ejemplo: en juicios legales, es preferible evitar condenar a inocentes (baja FP), aunque algunos culpables escapen.\n","\n","- **Desventajas de la Especificidad**\n","\n","  - No considera los falsos negativos (FN). Un modelo con alta especificidad puede fallar en detectar muchos casos positivos. Por ejemplo: Si un test de cáncer prioriza especificidad sobre sensibilidad, muchos pacientes enfermos podrían quedar sin diagnóstico.\n","\n","  - No es útil en detección temprana de enfermedades o fraudes. En casos donde es crítico detectar todos los positivos, la especificidad puede ser menos importante que el recall. Ejemplo: En detección de fraude bancario, preferimos marcar algunos falsos positivos que perder fraudes reales.\n","  \n","  - No funciona bien si la clase negativa es mucho más frecuente. En un dataset desbalanceado, la especificidad puede parecer alta simplemente porque hay muchos negativos.\n","\n","<FONT SIZE=5 COLOR=\"blue\"> 5. F1-Score </FONT>\n","\n","- Esta una métrica muy empleada porque nos resume la precisión y sensibilidad en una sola métrica, es decir, combina a precision con recall. Por ello es de gran utilidad cuando la distribución de las clases es desigual, por ejemplo cuando el número de pacientes con una condición es del 15% y el otro es 85%.\n","\n","- Es la media armónica de precision y recall. Esto implica que penaliza valores muy dispares entre estas métricas\n","\n","$$F1 = \\dfrac{2*precision*recall}{precision+recall} $$\n","\n","$$ F1= \\dfrac{2}{ \\dfrac{1}{precision}+\\dfrac{1}{recall}} $$\n","\n","- **Ventajas del F1-Score**\n","\n","   - Equilibra precisión y recall. Es útil cuando una métrica es mucho más alta que la otra. Evita que un modelo con alta precisión y bajo recall o alto recall y baja precisión tenga una puntuación engañosa.\n","\n","   - Funciona bien en datos desbalanceados. Accuracy no es útil en datasets desbalanceados, pero F1-score sí.\n","\n","   - Fácil de interpretar y comparar entre modelos.\n","\n","Si un modelo tiene mejor F1-score que otro, en general es superior.\n","\n","- **Desventajas del F1-Score**\n","\n","   - No diferencia entre falsos positivos y falsos negativos. En algunos casos, los FN son más costosos que los FP (ej. detección de cáncer). En otros casos, los FP son más costosos que los FN (ej. detección de fraude bancario).\n","\n","   - No considera la especificidad.  No mide qué tan bien el modelo predice los negativos correctamente.\n","\n","   - Puede ser engañoso en ciertos casos. Si los costos de FP y FN son muy diferentes, es mejor analizar precisión y recall por separado.\n","\n","\n","***Algunas observaciones (resumen)***:\n","\n","**Alta precisión y alto recall**: el modelo de Machine Learning escogido maneja perfectamente esa clase.\n","\n","**Alta precisión y bajo recall**: el modelo de Machine Learning escogido no detecta la clase muy bien, pero cuando lo hace es altamente confiable.\n","\n","**Baja precisión y alto recall**: El modelo de Machine Learning escogido detecta bien la clase,  pero también incluye muestras de la otra clase.\n","\n","**Baja precisión y bajo recall**: El modelo de Machine Learning escogido no logra clasificar la clase correctamente.\n","\n","- Cuando se tiene un conjunto de datos con clases **desbalanceadas**, suele ocurrir que obtenemos un alto valor de precisión en la clase mayoritaria y un bajo recall en la clase minoritaria.  En el campo de la salud esta circunstancia es particularmente frecuente y se debe recurrir al balanceo de clases.\n","\n","- La precisión es un gran estadístico, pero es útil únicamente cuando se tienen conjuntos de datos simétricos (la cantidad de casos de la clase 1 y de las clase 2 tienen magnitudes similares)\n","\n","- El indicador F1 de la matriz de confusión es útil si se tiene una distribución de clases desigual.\n","\n","- Elija mayor precisión para conocer qué tan seguro está de los verdaderos positivos, Mientras que la sensibilidad o “Recall” le servirá para saber si no está perdiendo positivos.\n","\n","- Las Falsas Alarmas:  Por ejemplo,  si cree que es mejor en su caso tener falsos positivos que falsos negativos, utilice una sensibilidad alta  (Recall) , cuando la aparición de falsos negativos le resulta inaceptable pero no le importa tener falsos positivos adicionales (falsas alarmas). Un ejemplo de esto es:  Prefieres que algunas personas sanas sean etiquetadas como diabéticas en lugar de dejar a una persona diabética etiquetada como sana.\n","\n","- Elija precisión (precision en inglés)  si quiere estar más seguro de sus verdaderos positivos. por ejemplo, correos electrónicos no deseados.  En este caso se prefiere tener algunos correos electrónicos “no deseados” en su bandeja de entrada en lugar de tener correos electrónicos “reales” en su bandeja de SPAM.\n","\n","- Elija alta Especificidad si desea identificar los verdaderos negativos, o lo que es igual cuando no desea falsos positivos. Por ejemplo conductores y las pruebas de alcoholemia\n","\n","Referencia : https://www.juanbarrios.com/la-matriz-de-confusion-y-sus-metricas/\n","\n"],"metadata":{"id":"z68RGh9Zag1l"}},{"cell_type":"markdown","metadata":{"id":"zxREriCb9iH5"},"source":["Con base a lo anterior vamos a construir la matriz de confusión"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h6a-VWvC1KwN"},"outputs":[],"source":["# construcción de la matriz de confusión\n","from sklearn import metrics\n","metrics.confusion_matrix(y_test, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"wq2cPiiYtaRu"},"source":["Una versión más elaborada de la matriz de confusión."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LWYlILDN6llf"},"outputs":[],"source":["MC= metrics.confusion_matrix(y_test, y_pred)\n","p = sns.heatmap(pd.DataFrame(MC),                    # data.frame\n","                annot=True,                          # colocar números de las cajitas\n","                annot_kws = {'size':20},             # tamaño de la letra\n","                cmap=\"YlOrRd\",                       # color de la letra 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu'\n","                fmt='g')                             # para que salgan los número no : notación científica\n","plt.title('Matriz de Confusión en test', y=1.1)\n","plt.ylabel('Valores Reales')\n","plt.xlabel('Predicciones')"]},{"cell_type":"markdown","metadata":{"id":"Nx2INYvf96ks"},"source":["Vamos a calcular las métricas mencionadas anteriormente:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dwJFuSFY91bT"},"outputs":[],"source":["#accuracy score\n","# nombre de las métricas\n","metrics=[\"accuracy\", \"recall\" , \"specificidad\", \"precision\", \"f1\"]\n","# valores\n","values = [accuracy_score(y_test,y_pred),\n","          recall_score(y_test,y_pred),\n","          specificity_score(y_test,y_pred),\n","          precision_score(y_test,y_pred),\n","          f1_score(y_test,y_pred)]\n","pd.DataFrame({\"metrics\": metrics , \"values\" : values})"]},{"cell_type":"markdown","source":["| Métrica   | ¿Por qué es importante en detección de diabetes? |\n","|---------- |---------|\n","| Recall       | Es clave porque queremos detectar todos los pacientes con diabetes y minimizar los falsos negativos (FN). <br> Un FN significaría que un paciente enfermo no recibe tratamiento a tiempo.  |\n","| F1-Score    | Si hay un desbalance en los datos (pocos casos positivos), ayuda a equilibrar precisión y recall.<br> Evita que un modelo con alta precisión pero bajo recall o viceversa sea engañoso.   |\n","| Precision    | Es importante, pero no tan prioritaria como el recall. <br>Un alto recall puede generar algunos falsos positivos (FP), pero es preferible hacer más pruebas a pacientes <br> falsamente etiquetados con diabetes que dejar enfermos sin diagnóstico.   |\n","| Especificidad    | Puede ser útil, pero no es la métrica principal. <br>Si la especificidad es demasiado alta, podría significar que el modelo no detecta suficientes casos de diabetes.   |"],"metadata":{"id":"XsR2nxt-WlOS"}},{"cell_type":"markdown","metadata":{"id":"xhci7d2O-AbN"},"source":["Otra forma de revisar las métricas es con el *classification_report*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9QlAzMIg-DWS"},"outputs":[],"source":["print(classification_report(y_test,y_pred))"]},{"cell_type":"markdown","metadata":{"id":"-ehqc7RMAEE2"},"source":["**Conclusiones**:\n","\n","- El modelo está clasificando bien al $73\\%$ de los registros. No es un valor muy alto.\n","\n","- El *recall* es $0.47$, es decir, de las personas que tienen diabetes, el algoritmo detecta correctamente un $45\\%$. El algoritmo no es tan bueno detectando personas con diabetes en los que sí tienen la enfermedad.\n","\n","- Se recomienda, tratar de optimizar los hiperparámetros o utilizar otro modelo."]},{"cell_type":"markdown","metadata":{"id":"FAzMR4_0-zDH"},"source":["# <FONT SIZE=5 COLOR=\"Purple\"> 6. Predicción en KNN </FONT>\n","\n"]},{"cell_type":"markdown","source":["Aunque el rendimiento del modelo no es el mejor, vamos a mostrar como se haría una predicción de un valor nuevo."],"metadata":{"id":"0qBH0xIr-uqP"}},{"cell_type":"markdown","metadata":{"id":"1yvrS3bbM8ph"},"source":["Particularmente, en estos algoritmos en los que se debe escalar, se deben escalar los valores a predecir. Este escalamiento se hace con base a $X_{train}$.\n","\n","Supongamos que queremos predecir si una paciente es propensa a tener diabetes o no, con los siguientes valores:\n","\n","- ***Pregnancies*** : 6\n","- ***Glucose*** : 148\n","- ***BloodPressure*** : 72\n","- ***SkinThikness*** : 35\n","- ***Insulin*** : 80\n","- ***BMI*** : 33.6\n","- ***DiabetesPedigreeFunction*** : 0.627\n","- ***Age*** : 50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wl4Owkwbt0S3"},"outputs":[],"source":["# representamos en forma de lista\n","[6,\t148,\t72,\t35,\t80,\t33.6,\t0.627, 50]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fxIS-_HLL8WG"},"outputs":[],"source":["# usamos la función escalar.transform\n","X_new = np.array([[6,\t148,\t72,\t35,\t80,\t33.6,\t0.627,\t50]])\n","X_test1 = escalar.transform(X_new)\n","X_test1"]},{"cell_type":"code","source":["KNN.predict(X_test1)"],"metadata":{"id":"zQq2Mrd7w4Aa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora bien, podemos ver los vecinos más cercanos a este valor"],"metadata":{"id":"HjXjjoyMw_2V"}},{"cell_type":"code","source":["from sklearn.neighbors import NearestNeighbors\n","# ver los vecinos más cercanos\n","distancias, indices = KNN.kneighbors(X_test1,\n","                                     n_neighbors=10,\n","                                     return_distance=True)"],"metadata":{"id":"WgIxaZqsxFrv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vecinos_cercanos = X_train.iloc[indices[0]]\n","vecinos_cercanos[\"distancias\"] = distancias[0]\n","vecinos_cercanos[\"resultados_vecinos\"] = y_train.iloc[indices[0]]\n","vecinos_cercanos"],"metadata":{"id":"R7o4edutB7EB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EsJ8N4Xju6UW"},"source":["# <FONT SIZE=5 COLOR=\"purple\"> 7. Validación Cruzada </FONT>\n","\n","La **validación cruzada**, o *cross validation*, es una técnica utilizada para evaluar los resultados obtenidos de un modelo de *machine learning* y garantizar que son independientes de los conjuntos de entrenamiento ($X_{train}$) y prueba ($X_{test}$).\n","\n","- Cuando usamos la función de *sklearn*:\n","\n","$$train\\_test\\_split(X, y, random\\_state = 123 )$$\n","\n","se extraen dos muestras aleatorias como conjuntos de entrenamiento y prueba. Luego se hace el proceso de entrenamiento y validación del modelo, teniendo como referencias las muestras seleccionadas. Sin embargo, una pregunta natural es:\n","\n","**¿Qué sucede si tomo otras muestras como conjunto de entrenamiento y de prueba, obtendré los mismos resultados?**\n","\n","Para responder lo anterior, debemos seleccionar varias muestras que correspondan a conjunto de entrenamiento y prueba diferentes y hacer el análisis del modelo. Precisamente, esto es lo que hace el proceso de validación cruzada.\n","\n","Se divide el conjunto de datos en $n$ partes, de las cuales se toma una como conjunto de *prueba* y las otras $n-1$ como conjunto de entrenamiento. Y vamos rotando el conjunto de prueba, tal y como se muestra en la siguiente figura.\n","\n","<br>\n","\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/val_cruzada/validation1.png?raw=true?\" alt=\"centered image\" width=\"600\" height=\"350\"></center>\n","\n","<br>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H-KzaKC8uzNV"},"outputs":[],"source":["# Validación cruzada k fold\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.pipeline        import make_pipeline\n","\n","pipeline = make_pipeline(StandardScaler(), KNN)\n","\n","#kfold_validacion = KFold(10)                              # divide los datos en 10 pliegues.\n","resultados = cross_val_score(pipeline,                     # modelo aplicado\n","                             X,                            # conjunto de predictores\n","                             y,                            # variable de respuesta\n","                             cv = 10,                       # número de divisiones en cross-validation.\n","                             scoring = \"accuracy\")         # se puede escoger la métrica.\n","print(resultados)                                          # para ver la variable resultados.\n","resultados.mean()"]},{"cell_type":"markdown","source":["Obtenemos en promedio 0.74 de *Accuracy*"],"metadata":{"id":"AqSX7kd518Ha"}},{"cell_type":"markdown","source":["# <FONT SIZE=5 COLOR=\"purple\"> 8. Parámetro vs Hiperparámetro </FONT>\n","\n","Iniciaremos definiendo los siguientes conceptos:\n","\n","**Parámetros**:\n","\n","- Son variables propias del modelo y que se obtienen de forma automática usando el conjunto de entrenamiento. Es decir, se estiman a partir de los datos.  \n","\n","- Por ejemplo, en regresión lineal buscamos una ecuación de la forma $y= \\beta_1 x +\\beta_0$ y precisamente este tipo de modelo nos ayuda a encontrar estos valores de $\\beta_1$ y $\\beta_0$.\n","\n","***Hiperparámetros:***\n","\n","- Son parámetros de aprendizaje automático que se eligen antes de iniciar el proceso de aprendizaje automático.\n","\n","- Son variables externas al modelo que no se obtienen automáticamente a partir de los datos.\n","\n","- Son ajustables y pueden afectar directamente a la forma en la que se entrena un modelo de aprendizaje automático.\n","\n","Algunos de estos hiperparámetros son:\n","\n","- *Número de vecinos en knn*\n","\n","- *Número de épocas en redes neuronales*\n","\n","- *Número de ramas en un árbol de decisión*\n","\n","- *Número de clústeres en un algoritmo de agrupamiento*\n","\n","- *Tipo de kernel en SVM*\n","\n","Los hiperparámetros son flexibles, ya que se refieren a cualquier elemento en el machine learning y el deep learning que decida sus valores o elija su configuración antes de que comience el entrenamiento y cuyos valores permanecen iguales cuando se finaliza el entrenamiento.\n","\n","Los parámetros, por su lado, son características inherentes al modelo. Esto quiere decir que se aprenden o se estiman a partir de los datos brindados durante el entrenamiento, ya que el algoritmo que se use intentará aprender a partir de las características de entrada y la variable objetivo.\n","\n","**Hiperparámetros de KNN**\n","\n","Particularmente en el algoritmo de ***knn***, k-vecinos más cercanos tenemos los siguientes hiperpámetros.\n","\n","- El ***número de vecinos*** $k$.\n","\n","- Las ***métricas***. Las más clásicas se pueden seleccionar entre:\n","\n","   - Euclideana\n","   - Manhattan\n","   - Minkowski\n","\n","- Los ***pesos*** en las métricas.\n","\n","   - Uniformes\n","   - Respecto a la distancia.  \n","\n","Podemos ver la documentación para ampliar la información\n","\n","[ALGORITMO KNN-sklearn 🌎](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n"],"metadata":{"id":"FBMrMB6wZkEb"}},{"cell_type":"markdown","metadata":{"id":"LjQ39YTuvG6w"},"source":["# <FONT SIZE=5 COLOR=\"purple\"> 9. Búsqueda en Grilla </FONT>\n","\n","- La ***búsqueda en grilla*** (grid search) es un método que busca las mejores combinaciones de hiperparámetros que hacen que un modelo tenga el error más bajo, es decir, estimaciones más precisas.\n","\n","- En cada combinación de hiperparámetros, la búsqueda en grilla aplica el proceso de *cross-validation* con el fin de dar una mejor evaluación del modelo en cada punto.\n","\n","- Cuando hablamos de búsqueda en grilla tenemos algunas alternativas: Grid Search y Random Grid Search. La primera se denomina propiamente *Grid Search* y en este método, se toman todas las combinaciones posibles de los hiperparámetros que se van a revisar. Como se ilustra en la siguiente gráfica.\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/val_cruzada/grid1.png?raw=true?\" alt=\"centered image\" width=\"600\" height=\"350\"></center>\n","<br>"]},{"cell_type":"markdown","source":["- Por otro lado, tenemos el ***Random Search***, que es una versión del primero donde no se toman todas las combinaciones de hiperparámetros sino que se selecciona una determinada cantidad aleatoria de combinaciones. Este método es útil cuando se tienen muchos hiperparámetros y el procesamiento puede demorarse.\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/val_cruzada/grid2.png?raw=true?\" alt=\"centered image\" width=\"600\" height=\"400\"></center>"],"metadata":{"id":"7o07dgnqbLSu"}},{"cell_type":"markdown","source":["Para hacer la búsqueda en grilla, vamos a considerar los siguientes parámetros\n","\n","1. El número de vecinos $k$ : [1,20]\n","2. Las métricas : *euclideana* y *manhattan*\n","3. Los pesos: \"uniformes\" o basados en \"distancia\"\n","\n","De acuerdo con lo anterior tenemos\n","\n","$$(20 \\, vecinos) \\times ( 2 \\, metricas) \\times ( 2 \\, pesos) = 80$$\n","\n","combinaciones de parámetros."],"metadata":{"id":"OFU9XmRsbiY2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OGSluflxvR2v"},"outputs":[],"source":["from sklearn.pipeline import Pipeline\n","\n","# Crear pipeline con escalador y modelo\n","pipe = Pipeline([\n","    (\"scaler\", StandardScaler()),\n","    (\"knn\", KNeighborsClassifier())\n","])\n","\n","# definimos los parámetros que vamos a combinar. Diccionario\n","grid_params = {\"knn__n_neighbors\" : list(range(1, 21)),         # se recorre la lista en k\n","               \"knn__weights\" : [\"uniform\",\"distance\"],         # se establecen los pesos\n","               \"knn__metric\" : [\"euclidean\",\"manhattan\"]}       # se establecen las métricas\n","\n","# hacemos la búsqueda en grilla con 5-folds\n","Grid_Search = GridSearchCV(pipe,                                     # el modelo aplicado\n","                           grid_params,                             # los parámetros que van a variar\n","                           cv = 10,                                 # el número de folds\n","                           verbose = 3)                             # para que imprima resultados. Posibilidades: 1,2 o 3\n","# Entrenar el modelo obtenido arriba\n","g_res = Grid_Search.fit(X_train,y_train)"]},{"cell_type":"markdown","metadata":{"id":"Fz22advXvpOQ"},"source":["Ahora, buscamos el mejor *score*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nx9iLativXJf"},"outputs":[],"source":["print(\"Mejor score: \",g_res.best_score_)"]},{"cell_type":"markdown","metadata":{"id":"NByeZ0aSvp2Q"},"source":["Finalmente, los hiperparámetros que lograron ese *score*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PDROtYIzvaZK"},"outputs":[],"source":["print(\"Mejores hiperparámetros\", g_res.best_params_)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1x_sHZ2G9k-VgzO35fOyjdECgPGZW5Cqk","timestamp":1692975942100}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}