{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-3uvcZUt3WC0"},"outputs":[],"source":["%%html\n","<center><marquee style='width: 60%; color: blue;'><b>‚úå ¬°Hola a todos! Hoy es una clase importante ‚úå </b></marquee><center>"]},{"cell_type":"markdown","metadata":{"id":"MmQviC6rC1ms"},"source":["<table>\n","    <tr>\n","        <td><img src=\"https://www.acofi.edu.co/eiei2016/wp-content/uploads/2016/09/Logo-Universidad-EIA.jpg\" width=\"250\"/></td>\n","        <td>&nbsp;</td>\n","        <td>\n","        <td><img src=\"https://raw.githubusercontent.com/Fabian830348/Bases_Datos/refs/heads/master/Logo_EICT_horizontal_ESPANOL%20(1).png\" width=\"300\"/></td>\n","        <td>&nbsp;</td>\n","        <td>\n","            <h1 style=\"font-size:200%;color:blue;text-align:center\">    <FONT COLOR=\"blue\"> Conceptos Machine Learning </p> Clasificaci√≥n  </FONT>         </h1></td>         \n","        <td>\n","            <tp><p style=\"font-size:99%;text-align:center\">Machine Learning </p></tp>\n","            <tp><p style=\"font-size:115%;text-align:center\">Diplomado 2025-2</p></tp>\n","            <tp><p style=\"font-size:115%;text-align:center\">Prof. Fabi√°n S√°nchez</p></tp>\n","        </td>\n","    </tr>\n","</table>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Ltcxu19TC-Vx"},"source":["# <FONT SIZE=4 COLOR=\"purple\"> 1. Objetivos de la sesi√≥n: </FONT>\n","\n","‚úî  En esta sesi√≥n revisaremos algunos conceptos fundamentales de Machine Learning como por ejemplo, conjunto de entrenamiento, conjunto de prueba, m√©trica de evaluaci√≥n, validaci√≥n cruzada (cross-validation),  hiperpar√°metros, entre otros.\n","\n","‚úî Por otro lado, estudiaremos en qu√© consisten los problemas de clasificaci√≥n y estudiaremos el primer modelo cl√°sico de este tipo: los *k-vecinos m√°s cercanos*. Adem√°s, revisaremos la matriz de confusi√≥n y las diferentes m√©tricas como el *recall* , *accuracy*, *precision*, etc.\n"]},{"cell_type":"markdown","metadata":{"id":"M0hu572uGmEi"},"source":["# <FONT SIZE=4 COLOR=\"purple\"> 2. Conceptos b√°sicos de Machine Learning </FONT>\n","\n","En est√° secci√≥n revisaremos algunos conceptos b√°sicos de machine learning.\n","\n","<FONT SIZE=3 COLOR=\"green\"> a. Algoritmos de clasificaci√≥n: </FONT>  t√©cnicas de aprendizaje supervisado para hacer predicciones sobre una variable objetivo $\\mathbf{y}$ que es categ√≥rica o discreta con pocos valores.\n","\n","\n","<center><FONT SIZE=4 COLOR=\"BLUE\">Situaci√≥n 1 </FONT></center>\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/d6bb35cb0a6e29c3995fa8a88c83ec24cf2bc6e8/SVM/svm5.png?raw=true\" alt=\"centered image\" width=\"700\" height=\"300\"></center> <center><figcaption> <FONT SIZE=1 COLOR=\"black\"> Fuente: Elaboraci√≥n propia  </FONT> <figcaption></center>\n","<br>\n","\n","<center><FONT SIZE=4 COLOR=\"BLUE\">Situaci√≥n 2 </FONT></center>\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/d6bb35cb0a6e29c3995fa8a88c83ec24cf2bc6e8/SVM/svm6.png?raw=true\" alt=\"centered image\" width=\"700\" height=\"300\"></center> <center><figcaption> <FONT SIZE=1 COLOR=\"black\"> Fuente: Elaboraci√≥n propia  </FONT> <figcaption></center>\n","<br>\n","\n","<FONT SIZE=3 COLOR=\"green\"> b. Variable Objetivo: </FONT> tambi√©n denominada **variable de respuesta**. En un algoritmo de aprendizaje de m√°quina supervisado, es la variable que queremos predecir (por lo general, denotada como $\\mathbf{y}$). Esta puede ser discreta o continua. En el primer caso, da lugar a algoritmos de ***clasificaci√≥n*** y en el segundo caso a algoritmos de ***regresi√≥n***.\n","\n","<br>\n","\n","<FONT SIZE=3 COLOR=\"green\"> c. Variable(s) Predictora(s): </FONT> tambi√©n denominada ***features*** o caracter√≠sticas, son las variables que se usar√°n para predecir la variable objetivo. Estas se denotan como\n","\n","$$\\mathbf{X}=\\{X_1,X_2, \\dots, X_n \\}$$\n","\n","<br>\n","\n","<FONT SIZE=3 COLOR=\"green\"> d. Conjunto de Entrenamiento: </FONT> es el subconjunto de registros que se selecciona para entrenar el modelo. Este conjunto consta de dos partes:\n","\n","- $X_{train}$ : conjunto de entrenamiento de los predictores o *features*.\n","\n","- $y_{train}$: conjunto de entrenamiento de la variable objetivo asociada al conjunto $X_{train}$.\n","\n","El conjunto de entrenamiento se selecciona de manera aleatoria y por lo general se toma el $70\\%$ , $75\\%$ y $80 \\%$.\n","\n","<br>\n","\n","<FONT SIZE=3 COLOR=\"green\"> e. Conjunto de Prueba: </FONT>: Es el subconjunto de registros que se selecciona para validar el modelo. Consta de dos partes:\n","\n","- $X_{test}$ : conjunto de validaci√≥n de los predictores o *features*.\n","\n","- $y_{test}$: conjunto de validaci√≥n de la variable objetivo asociada al conjunto $X_{test}$.\n","\n","El tama√±o de este conjunto es el complemento del conjunto de entrenamiento.\n","\n","**Nota:** para algoritmos cl√°sicos de machine learning se acostumbra dividir en entrenamiento y prueba. Sin embargo, en algoritmos m√°s complejos que requieren el entrenamiento de mucho par√°metros, como es el caso de las redes neuronales, se acostumbra dividir en tres partes: *train* , *validation* and *test*.\n","\n","<center><FONT SIZE=4 COLOR=\"BLUE\"> ESQUEMA GENERAL DE CLASIFICACI√ìN EN MACHINE LEARNING </FONT></center>\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Intro-knn/ESQUEMA%20DE%20CLASIFICACI%C3%93N.png?raw=true\" alt=\"centered image\" width=\"700\" height=\"400\"></center> <center><figcaption> <FONT SIZE=1 COLOR=\"black\"> Fuente: Elaboraci√≥n propia  </FONT> <figcaption></center>\n","<br>\n","\n","<br>\n","\n","<FONT SIZE=3 COLOR=\"green\"> f. Matriz de Confusi√≥n:</FONT> Herramienta usada para evaluar el rendimiento del modelo. (se ampliar√° m√°s adelante las m√©tricas y conceptos).\n","\n","<br>\n","\n","<FONT SIZE=3 COLOR=\"green\"> g. Hiperpar√°metro: </FONT> son variables de configuraci√≥n externa al modelo original (general) que se pueden ajustar para entrenar el modelo. (cada modelo tiene diferentes hiperpar√°metros)"]},{"cell_type":"markdown","metadata":{"id":"AYn5w5oBqtzP"},"source":["A continuaci√≥n, revisaremos en detalle uno de los primeros algoritmos de machine learning y con este ilustraremos algunos conceptos y herramientas que aplican tambi√©n para otros algoritmos de clasificaci√≥n."]},{"cell_type":"markdown","metadata":{"id":"0TnsrU_7kbgR"},"source":["# <FONT SIZE=4 COLOR=\"Purple\"> 3. Algoritmo de clasificaci√≥n KNN : K-vecinos m√°s cercanos </FONT>\n","\n","En esta secci√≥n revisaremos el algoritmo de clasificaci√≥n ***KNN: k-nearest neighbors*** : K-vecinos m√°s cercanos."]},{"cell_type":"markdown","metadata":{"id":"z6UUUh63lb0P"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 3.1 ¬øEn qu√© consiste? </FONT>\n","\n","Este algoritmo consiste en clasificar los valores de una variable categ√≥rica de acuerdo con los vecinos m√°s cercanos. A continuaci√≥n explicaremos el funcionamiento"]},{"cell_type":"markdown","metadata":{"id":"vcCknbLpmz51"},"source":["1. Supongamos que queremos clasificar el cuadrado amarillo en las dos posibles clases.\n","\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Intro-knn/knn1.png?raw=true?\" alt=\"centered image\" width=\"600\" height=\"450\"></center> <center><figcaption> <FONT SIZE=1 COLOR=\"black\"> Fuente: Libro Gu√≠a  </FONT> <figcaption></center>\n","\n","\n"]},{"cell_type":"markdown","source":["La decisi√≥n se toma por la clase mayoritaria que hay en la vecindad."],"metadata":{"id":"T_zRwPbQkx_Q"}},{"cell_type":"markdown","metadata":{"id":"Rr63K3NRoDx9"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 3.2 Descripci√≥n del algoritmo: pseudoc√≥digo </FONT>\n","\n","- Determinar el valor de $k$.\n","\n","- Calcular la distancia del punto a clasificar a todos los otros puntos.\n","\n","- Ordenar de manera ascendente las distancias.\n","\n","- Tomar los puntos m√°s cercanos al punto a clasificar de acuerdo con el valor que le asignemos a $k$.\n","\n","- Contar cu√°ntos puntos de cada clase est√°n en la vecindad y definimos por mayor√≠a.\n","\n","- Por ejemplo: Si $k$ es 3 y tenemos\n","\n","   + Distancia 1 : 2.5 : clase a\n","\n","   + Distancia 2 : 2.51 : clase b\n","\n","   + Distancia 3 : 2.53 : clase a\n","\n","  Conclusi√≥n: El punto se clasifica en la clase a.\n","\n","En caso de que haya empate se pueden definir algunos criterios de desempate. Por ejemplo:\n","\n","  - la clase que contenga al vecino m√°s cercano.\n","  - la clase con la distancia media m√°s peque√±a."]},{"cell_type":"markdown","metadata":{"id":"Wa22mH3xnPJf"},"source":["Con base al funcionamiento del√± algoritmo de *kNN* podemos observar que es sennsible al valor asignado a $k$.\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Intro-knn/knn2.png?raw=true?\" alt=\"centered image\" width=\"600\" height=\"450\"></center> <center><figcaption> <FONT SIZE=1 COLOR=\"black\"> Fuente: Libro Gu√≠a  </FONT> <figcaption></center>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"uJOahxNMW7mZ"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 3.3 Sobre el algoritmo </FONT>\n","\n","A continuaci√≥n, algunos puntos importantes que se deben tener en cuenta sobre el algoritmo ***knn***\n","\n","1. Observe que no se genera un modelo que sea consecuencia de un entrenamiento previo, sino que el aprendizaje se da en el mismo momento en el que se prueban los datos de validaci√≥n. A este tipo de algoritmos se les denomina ***lazy learning methods***.\n","\n","2. Como utiliza todo el set de entrenamiento para calcular las distancias, se tiene un costo computacional alto.\n","\n","3. Es un algoritmo que da buenos resultados, pero es recomendable para conjuntos de datos no tan grandes.\n","\n","4. Es muy sensible al valor de $k$ y a la distancia seleccionada.\n","\n","5. Es importante escalar los datos."]},{"cell_type":"markdown","metadata":{"id":"E2oMMh1Goqyr"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 3.4 Sobre las distancias </FONT>\n","\n","El algoritmo $knn$ est√° fundamentado en la distancia entre dos puntos. Si bien, una de las distancias m√°s conocida es la distancia euclideana, existen otras distancias que se pueden usar para el algoritmo.\n","\n","## <FONT SIZE=3 COLOR=\"magenta\"> Distancia Euclideana </FONT>\n","\n","$$ \\left (\\sum \\limits_{i=1}^n (x_i-y_i)^2 \\right)^{1/2}$$\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Intro-knn/dis_euclide.png?raw=true\" alt=\"centered image\" width=\"600\" height=\"300\"></center> <center><figcaption> <FONT SIZE=1 COLOR=\"black\"> Fuente: Elaboraci√≥n propia  </FONT> <figcaption></center>\n","<br>\n","\n","Esta m√©trica se puede usar para variables con valores discretos o continuos en general.\n","\n","## <FONT SIZE=3 COLOR=\"magenta\"> Distancia de Manhattan</FONT>\n","\n","$$ \\sum \\limits_{i=1}^{n} |x_i-y_i|$$\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Intro-knn/dis_manhattan.png?raw=true\" alt=\"centered image\" width=\"600\" height=\"300\"></center> <center><figcaption> <FONT SIZE=1 COLOR=\"black\"> Fuente: Elaboraci√≥n propia  </FONT> <figcaption></center>\n","<br>\n","\n","Observe que es m√°s sencilla que la euclideana (tiene menos c√°lculos)\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Intro-knn/knn3.png?raw=true?\" alt=\"centered image\" width=\"600\" height=\"450\"></center> <center><figcaption> <FONT SIZE=1 COLOR=\"black\"> Fuente: Elaboraci√≥n propia  </FONT> <figcaption></center>\n","\n","La m√©trica euclideana y de Manhattan tienen una generalizaci√≥n que se denomina.\n","\n","## <FONT SIZE=3 COLOR=\"magenta\"> Distancia de Minkowski</FONT>\n","\n","$$ \\left (\\sum \\limits_{i=1}^n |x_i-y_i|^p \\right)^{1/p}$$\n","\n","## <FONT SIZE=3 COLOR=\"magenta\"> Distancia de Hamming</FONT>\n","\n","$$Distancia \\,\\, Hamming : \\begin{cases} 0 & \\text{si $x=y$} \\\\ 1 & \\text{si $x \\neq y$}   \\end{cases}$$\n","\n","Esta distancia es equivalente a la de Manhattan para variables binarias, es decir, que solo tienen ceros y unos\n","\n","$$ a = \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 1 \\end{pmatrix}  \\qquad b = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$$\n","\n","## <FONT SIZE=3 COLOR=\"magenta\"> Distancia Euclideana con pesos </FONT>\n","\n","$$ \\left (\\sum \\limits_{i=1}^n w_i(x_i-y_i)^2 \\right)^{1/2}$$\n","\n","donde los pesos resultan, por ejemplo, del escalamiento de los datos.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Lypilljgelwo"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 3.5 Sobre los valores de $k$ </FONT>\n","\n","Un par√°metro muy importante en el algoritmo de *knn* es el valor de $k$.  Inicialmente, no hay una forma general de escogerlo, sin embargo\n","\n","- Si se toma un valor de $k$ muy peque√±o se puede sobreajustar (overfitting).\n","\n","- Si el valor de $k$ es muy grande sucede lo contrario. Ser√° m√°s dificil clasificar.\n","\n","- En clasificaci√≥n binaria se recomienda tomar $k$ impar para evitar empates. Iniciar con $k= 5,7,9 \\dots$\n","\n","- Un valor inicial que se puede tomar es $k=\\sqrt{n}$, donde $n$ es el n√∫mero de datos y a partir de este se ajusta el modelo.\n","\n","- Se recomienda **Tunear** (optimizar) el hiperpar√°metro $k$. Se dice hiperpar√°metro ya que es un par√°metro que se utiliza para entrenar el modelo."]},{"cell_type":"markdown","metadata":{"id":"yKuq0-jjgcgl"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 3.6 Sobre el escalamiento </FONT>\n","\n","El algoritmo *knn* est√° fundamentado en seleccionar m√≠nimas distancias, en ese orden de ideas, observe lo siguiente.\n","\n","- Si se tiene una variable $X_1$ que var√≠a en $[1,2]$ y otra variable $X_2$ que var√≠a en $[1000, 2000]$. Al calcular distancias con los valores de estas variables $X_2$ dominar√° a $X_1$ que tiene valores m√°s peque√±os y como el algoritmo utiliza la distancia para clasificar entonces queda sesgado el resultado.\n","\n","Por lo anterior, se deben escalar las variables predictoras y en general se usan las siguientes dos funciones.\n","\n","## <FONT SIZE=3 COLOR=\"blue\"> StandardScaler </FONT>\n","\n","$$\\dfrac{X-\\mu}{\\sigma}$$\n","\n","Se denomina estandarizaci√≥n\n","\n","## <FONT SIZE=3 COLOR=\"blue\"> MaxminScaler </FONT>\n","\n","$$\\dfrac{X-X_{min}}{X_{max}-X_{min}}$$\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dmBWtchOkxMQ"},"source":["A continuaci√≥n, revisaremos un ejemplo donde ilustraremos los conceptos, el c√≥digo de programaci√≥n y otros elementos importantes."]},{"cell_type":"markdown","metadata":{"id":"jU2O_Ocdk-MD"},"source":["# <FONT SIZE=5 COLOR=\"purple\"> 4. Ejemplo Pr√°ctico </FONT>\n","\n","- En esta secci√≥n haremos un ejemplo pr√°ctico.\n","\n","- Iniciaremos indicando las librer√≠as que debemos usar."]},{"cell_type":"markdown","metadata":{"id":"LQk9kTV1lZw0"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 4.1 Librer√≠as de trabajo </FONT>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fmJaik-Alf_S"},"outputs":[],"source":["# Manipulaci√≥n de data.frames\n","import pandas       as pd\n","import numpy        as np\n","\n","# Librer√≠as para Gr√°ficos\n","import matplotlib.pyplot  as plt\n","import seaborn            as sns\n","import plotly.express     as px\n","\n","# Librer√≠as para datos de entrenamiento y prueba\n","from sklearn.model_selection    import train_test_split\n","\n","# Para preprocesamiento/escalar los datos\n","from sklearn.preprocessing      import StandardScaler, MinMaxScaler\n","\n","# Para aplicar k-nearest neighbors\n","from sklearn.neighbors          import KNeighborsClassifier\n","from sklearn.linear_model       import LogisticRegression\n","from sklearn.tree               import DecisionTreeClassifier\n","\n","# M√©tricas de evaluaci√≥n\n","from sklearn                    import metrics\n","from sklearn.metrics            import confusion_matrix, ConfusionMatrixDisplay, classification_report\n","from sklearn.metrics            import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score\n","from imblearn.metrics           import specificity_score\n","\n","# Optimizaci√≥n de hiperpar√°metros\n","from sklearn.model_selection    import GridSearchCV\n","\n","# Para ignorar los warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"HkINXW4WmU5O"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 4.2 Contexto del problema </FONT>\n","\n","En este caso, veremos un caso t√≠pico de problema de clasificaci√≥n. Queremos predecir si una integrante de una muestra que representa a una poblaci√≥n, tiene diabetes. Queremos hacer esto a partir de m√∫ltiples variables que tenemos de cada una de las pacientes:\n","\n","- ***Pregnancies***: N√∫mero de embarazos que ha tenido en su vida\n","- ***Glucose***: Nivel de concentraci√≥n de glucosa en sangre\n","- ***BloodPressure***: Presi√≥n arterial\n","- ***SkinThikness***: Espesor de piel a la altura del triceps\n","- ***Insulin***: Respuesta a dosis de insulina en 2 horas\n","- ***BMI***: √çndice de masa corporal\n","- ***DiabetesPedigreeFunction***: Presencia de diabetes en ascendencia directa\n","- ***Age***: Edad del paciente\n","- ***Outcome***: Variable que queremos predecir:\n","   - $1$ : Tiene diabetes\n","   - $0$ : No tiene diabetes\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gvKTG0D5pHv9"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 4.3 Importar los datos </FONT>\n","\n","Lo primero que haremos es importar los datos que est√°n en el siguiente link o pueden ser descargados de la p√°gina de Kaggle.\n","\n","https://raw.githubusercontent.com/Fabian830348/Bases_Datos/master/diabetes.csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gPKIEFqGqDJn"},"outputs":[],"source":["url = \"https://raw.githubusercontent.com/Fabian830348/Bases_Datos/master/diabetes.csv\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TCkook-pqDG3"},"outputs":[],"source":["diabetes= pd.read_csv(url)"]},{"cell_type":"code","source":["diabetes.head()"],"metadata":{"id":"Y_2sExAnAvom"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wlgRkB50rYvW"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 4.4 Exploraci√≥n r√°pida de los datos </FONT>\n","\n","Antes de hacer cualquier modelo de machine learning o an√°lisis similar es fundamental entender y explorar las variables del conjunto de datos."]},{"cell_type":"code","source":["# cabeza de los datos (primeros)\n"],"metadata":{"id":"_HxOsJo6xx5r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# cola de los datos (√∫ltimo registros)\n"],"metadata":{"id":"ejhGdo4Sx0GV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# revisar las columnas de los datos\n"],"metadata":{"id":"74vN4faAyJZ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tama√±o de los datos\n"],"metadata":{"id":"f9ZBxTjNQCO6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# revisar la informaci√≥n de los datos\n"],"metadata":{"id":"CUzSNjbMyMtu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# estad√≠sticos descriptivos\n"],"metadata":{"id":"WxO1qrUVySvy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora, vamos a hacer dos pasos adicionales de alistamiento del conjunto de datos:\n","\n","1. vamos a cambiar el nombre de la variable Outcome por Resultado\n","\n","2. Vamos a explorar la variable objetivo"],"metadata":{"id":"OQWqFO-EyXzB"}},{"cell_type":"code","source":["diabetes.head()"],"metadata":{"id":"5czon2XUS_ps"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# cambiar el nombre de la variable objetivo\n","# inplace : sobreescribir o no\n","diabetes.rename(columns = {\"Outcome\" : \"resultado\"}, inplace = True)"],"metadata":{"id":"Q5S8E607yjAB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["diabetes.head()"],"metadata":{"id":"Z6dp-Omzy88E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vamos a revisar la variable objetivo"],"metadata":{"id":"rJsJZtUDRzQ_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"uoFRd8uMqTNB"},"outputs":[],"source":["# contar las categorias de la variable resultado\n","diabetes.resultado.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"hS0mIidmxVYL"},"source":["Hacemos la gr√°fica de barras de las frecuencias"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JqTnwtMuqdXB"},"outputs":[],"source":["# gr√°fica con plotly express\n","px.bar(diabetes.resultado.value_counts(),\n","       color = [\"no\", \"si\"])"]},{"cell_type":"code","source":["px.pie(diabetes,\n","       names = \"resultado\" )"],"metadata":{"id":"ZFw8uf_v38y7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rDxGEnEswVeV"},"source":["**Cuidado üç≥**: En esta parte hay que tener especial atenci√≥n,  particularmente en otros algoritmos. Cuando los datos est√°n desbalanceados pueden afectar los resultados. Para esto se puede usar algunas t√©cnicas de balanceo de datos: *subsampling*, *oversampling* y *smote*.\n","\n","- Para continuar con el ejercicio, trabajaremos con las clases como est√°n."]},{"cell_type":"markdown","source":["Otras gr√°ficas"],"metadata":{"id":"ohFf6g94uuJl"}},{"cell_type":"code","source":["# tabla de frecuencias de la variable *pregnancies*\n","diabetes.Pregnancies.value_counts()"],"metadata":{"id":"8Ux8W-cAu82q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# gr√°fico de barras de la variable *Pregnancies*\n","px.bar(diabetes.Pregnancies.value_counts())"],"metadata":{"id":"az99CZJ5vVBo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Podemos observar que la concentraci√≥n de registros est√°n en pacientes de 0,1 y 2 embarazos."],"metadata":{"id":"aQHJd8WEx0jN"}},{"cell_type":"code","source":["# boxplot de la variable edad\n","px.box(diabetes,\n","       y = \"Age\")"],"metadata":{"id":"r80VbACFuvtI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["De acuerdo con la gr√°fica anterior no hay datos at√≠picos por debajo del l√≠mite inferior. Por encima se presentan, algunos datos at√≠picos."],"metadata":{"id":"s6XOA5Lix8Nu"}},{"cell_type":"code","source":["# boxplot de la variable edad vs resultado\n","px.box(diabetes,\n","       y = \"Age\",\n","       x = \"resultado\",\n","       color = diabetes.resultado)"],"metadata":{"id":"fWk5FXVVxW23"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Se observa que en los pacientes con diabetes son mayores que los pacientes sin diabetes. Sin embargo hay algunas personas mayores que no tienen diabetes."],"metadata":{"id":"z_EWkLbCyHXz"}},{"cell_type":"code","source":["# histograma de la variable glucosa\n","px.histogram(diabetes,\n","             x = \"Glucose\")"],"metadata":{"id":"zQqyA00Hwea9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Se deja al lector que continue explorando m√°s gr√°ficas"],"metadata":{"id":"lW2pvIyexugz"}},{"cell_type":"markdown","metadata":{"id":"iod7SswDw-a3"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 4.5 Conjunto de Entrenamiento y Prueba </FONT>\n","\n","- **data training:** Datos que usamos para entrenar el modelo.\n","\n","- **testing data:** Datos que reservamos para comprobar si el modelo generado a partir de los datos de entrenamiento, funciona\n","\n","Normalmente, usamos $70\\%-30\\%$ / $80\\%-20\\%$"]},{"cell_type":"code","source":["diabetes.head()"],"metadata":{"id":"wKcifH2uAU_y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Primero le daremos nombre a la variable objetivo ($y$) y a las variables predictoras ($X$)."],"metadata":{"id":"3JuC3tLLzJBw"}},{"cell_type":"code","source":["diabetes.head()"],"metadata":{"id":"8trYhJp9xfde"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# la variable objetivo\n","y = diabetes[\"resultado\"]\n","# las variables predictoras\n","X = diabetes.drop(\"resultado\", axis=1)"],"metadata":{"id":"RC3VkBQmzP_A"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nueOG15Tqsfd"},"outputs":[],"source":["# Dividir en dos conjuntos: entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X,                        # variables predictoras\n","                                                    y,                        # variable de respuesta\n","                                                    stratify = y,             # garantiza que los resultados se distribuyan igual\n","                                                    random_state = 0,         # semilla para que al ejecutar siempre de igual\n","                                                    test_size = 0.3)          # tama√±o del conjunto de prueba (tambi√©n se puede train)"]},{"cell_type":"markdown","metadata":{"id":"q1LiaIp50Y2L"},"source":["Veamos los tama√±os de estos conjuntos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pJRMrfwi0e_g"},"outputs":[],"source":["print(\"El tama√±o del conjunto de datos {}\".format(diabetes.shape))\n","print(\"El tama√±o de X_train es {}\".format(X_train.shape))\n","print(\"El tama√±o de y_train es: {}\".format(y_train.shape))\n","print(\"El tama√±o de X_test es {}\".format(X_test.shape))\n","print(\"El tama√±o de y_test es: {}\".format(y_test.shape))"]},{"cell_type":"markdown","metadata":{"id":"b9nM26Ic0cQc"},"source":["Exploremos alguno de ellos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5W4WbOA5JAJe"},"outputs":[],"source":["# los primeros datos del conjunto de entrenamiento\n","X_train.head()"]},{"cell_type":"code","source":["# los primeros datos del conjunto de prueba\n","y_train.head()"],"metadata":{"id":"M8lye22V3FwZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_IvjR_fr0mBP"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 4.6 Escalar las variables predictoras </FONT>\n","\n","- En los algoritmos donde se vea involucrada una distancia es importante hacer el escalamiento.\n","\n","- Una recomendaci√≥n es hacer el escalamiento despu√©s de dividir en entrenamiento y prueba, ya que la idea es evitar el **data leakage** o fuga de datos.Esto es, cuando informaci√≥n del conjunto de prueba (test) se filtra hacia el conjunto de entrenamiento, haciendo que el modelo aprenda de datos que no deber√≠a conocer.\n","\n","- En este caso vamos a escalar todas las variables ya que son num√©ricas. Sin embargo, si el conjunto de variables predictoras contiene variables catag√≥ricas se recomienda no escalarla, ya que no son num√©ricas. En un pr√≥ximo ejemplo se revisara esta situaci√≥n.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NXOutoIs1CcK"},"outputs":[],"source":["# definimos la funci√≥n para escalar\n","escalar = StandardScaler()\n","# lo aplicamos a los conjuntos\n","X_train_s = escalar.fit_transform(X_train)\n","X_test_s = escalar.transform(X_test)"]},{"cell_type":"code","source":["X_train_s"],"metadata":{"id":"PDsNWYanekKu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aJncrGo-1F_R"},"source":["**Observaci√≥n importante de lo anterior**.\n","\n","a. Para $X_{train}$ usamos ***fit.transform*** esto significa que los datos de este conjunto se escalar√°n con base a su $\\mu$ media y $\\sigma$ desviaci√≥n est√°ndar. (que no son lo mismo que calcularla sobre todo el conjunto)\n","\n","b. Para $X_{test}$ usamos ***.transform*** esto significa que para escalar los datos del conjunto de prueba se usan los par√°metros $\\mu$ y $\\sigma$ obtenidos en la parte a. con el conjunto de entrenamiento $X_{train.}$\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Intro-knn/knn4.png?raw=true?\" alt=\"centered image\" width=\"600\" height=\"400\"></center> <center><figcaption> <FONT SIZE=1 COLOR=\"black\"> Fuente: Elaboraci√≥n propia  </FONT> <figcaption></center>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ImKRyOLx2vVs"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 4.7 Selecci√≥n de $k$  </FONT>\n","\n","- Inicialmente seleccionamos un valor un $k$, entrenamos el modelo y luego revisamos otros valores de $k$ para ver si tenemos mejores resultados."]},{"cell_type":"markdown","metadata":{"id":"j904Yynv3D7C"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 4.8 Generar el Modelo  </FONT>\n","\n","En esta parte usaremos la librer√≠a *sciki-learn* y la funci√≥n *KNeighborsClassifier*.\n","\n","Para generar el modelo tenemos m√∫ltiples alternativas, ya que podemos seleccionar:\n","\n","   - **k** : n√∫mero de vecinos. Por defecto $k=5$\n","   - La **m√©trica** : *manhattan* , *euclidean*, etc.\n","   - Los pesos **weights**: *uniform* y *distance*. Por defecto *uniform*\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EVHP8iWx3GKI"},"outputs":[],"source":["# definir el modelo\n","KNN = KNeighborsClassifier(n_neighbors = 10,         # n√∫mero de vecinos k=10\n","                           metric = 'euclidean',     # m√©trica euclideana\n","                           weights= \"uniform\")       # peso que se asigna a los datos"]},{"cell_type":"code","source":["# entrenar el modelo\n","KNN.fit(X_train_s,y_train)"],"metadata":{"id":"mo0als2agPYA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vamos a evaluar qu√© tan bien est√° haciendo la clasificaci√≥n el modelo"],"metadata":{"id":"-bvrrKPA3vQS"}},{"cell_type":"markdown","metadata":{"id":"PsoZTQB33j66"},"source":["## <FONT SIZE=4 COLOR=\"blue\"> 4.9 Evaluar en el conjunto de Prueba  </FONT>\n","\n","Luego de tener el modelo entrenado con $X_{train}$ y $y_{train}$ pasamos a calcularlo en el conjunto $X_{test}$, con lo cual obtendremos valores de predicci√≥n del modelo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y3LZQ9s63n1U"},"outputs":[],"source":["# se utiliza la funci√≥n .predict\n","y_pred = KNN.predict(X_test_s)\n","y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U__P1T43EgT_"},"outputs":[],"source":["# estos son los valores reales.\n","np.array(y_test)"]},{"cell_type":"markdown","metadata":{"id":"3Gzcmncd7CRx"},"source":["La pregunta que nos hacemos ahora es:\n","\n","***¬øQu√© tanta coincidencia hay en el modelo con los datos de prueba?***\n","\n","La respuesta a esta pregunta la tendremos justamente comparando **$y_{pred}$** con **$y_{test}$**. Esto lo haremos con una herramienta muy importante en Machine Learning y modelos de clasificaci√≥n denominada ***matriz de confusi√≥n***."]},{"cell_type":"markdown","metadata":{"id":"k36weu033utG"},"source":["# <FONT SIZE=5 COLOR=\"purple\"> 5. Matriz de Confusi√≥n </FONT>\n","\n","En el campo del Machine Learning la **matriz de confusi√≥n** es una herramienta que permite visualizar el desempe√±o de un algoritmo de clasificaci√≥n.\n","\n","- Las columnas de la matriz representa el n√∫mero de predicciones de cada clase.\n","\n","- Las filas representan las instancias en la clase real.\n","\n","Esta matriz permite ver qu√© tipos de aciertos y errores est√° teniendo nuestro modelo a la hora de pasar por el proceso de aprendizaje con los datos.\n","\n","En el siguiente gr√°fico se muestra lo anterior\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Imagen/metricas.png?raw=true\" alt=\"centered image\" width=\"500\" height=\"400\"></center>\n","<br>\n","\n","Para entender la matriz de confusi√≥n veamos algunas definiciones:\n","\n","**Verdadero positivo:** El valor real es positivo y la prueba predice tambi√©n que es positivo.\n","\n","- La persona estaba enferma y el modelo predice bien que estaba enferma. *Predicci√≥n correcta*\n","\n","**Verdadero negativo:** El valor real es negativo y la prueba predice tambi√©n que el resultado es negativo.\n","\n","- La persona no est√° enferma y el modelo predice que no est√° enferma. *Predicci√≥n correcta*\n","\n","**Falso negativo:** El valor real es positivo, y la prueba predice que el resultado es negativo.\n","\n","- La persona esta enferma y el modelo predice que no lo est√°. *predicci√≥n incorrecta* : error tipo II\n","\n","**Falso positivo:** El valor real es negativo, y la prueba predice que el resultado es positivo.\n","\n","- La persona no est√° enferma y el modelo predice que lo est√°. *predicci√≥n incorrecta* : error tipo I\n","\n","Veamos las m√©tricas que se utilizan para evaluar el modelo.\n","\n","\n"]},{"cell_type":"markdown","source":["## <FONT SIZE=5 COLOR=\"green\"> 5.1 M√©tricas Utilizadas para evaluar un modelo </FONT>\n","\n","<FONT SIZE=5 COLOR=\"blue\"> 1. Accuracy (exactitud) </FONT>\n","\n","- Es el porcentaje de predicciones correctas de todo el modelo.\n","\n","- Es la proporci√≥n de resultados verdaderos (tanto verdaderos positivos (VP) como verdaderos negativos (VN)) dividido entre el n√∫mero total de casos examinados (verdaderos positivos, falsos positivos, verdaderos negativos, falsos negativos)\n","\n","$$Accurary = \\dfrac{VP+VN}{VP+FN+VN+FP}$$\n","\n","Observaci√≥n: Si los datos est√°n desbalanceados se debe revisar con cuidado, ya que el rendimiento general puede ser alto, pero en una de las categorias o clases no se evidencian buenos resultados. Veamos el siguiente ejemplo\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Imagen/confusi√≥n_ej1.PNG?raw=true\" alt=\"centered image\" width=\"600\" height=\"400\"></center>\n","<br>\n","\n","- Se est√° detectando *spam* y el rendimiento del modelo es $94\\%$. Sin embargo, el *recall* es de solo el $16\\%$ que es la clase que quiero detectar\n","\n","<FONT SIZE=5 COLOR=\"blue\"> 2. Recall (sensibilidad) </FONT>\n","\n","Es el porcentaje de los casos positivos reales que fueron detectados correctamente por el modelo. Es decir es la tasa de verdaderos positivos o **True Positive Rate (TPR)**.\n","\n","$$recall = \\dfrac{VP}{VP+FN}$$\n","\n","- *En el √°rea de la salud se dice que la sensibilidad o recall es la capacidad de de poder detectar correctamente la enfermedad entre los enfermos*\n","\n","\n","- El *recall* prioriza la detecci√≥n de los casos positivos. Es conveniente usarlo cuando los falsos negativos resultan costosos para el contexto.\n","\n","- **Observaciones**: ¬øCu√°ndo usar esta m√©trica?\n","   \n","- Se usa si los falsos negativos son inaceptables en el contexto.\n","\n","   - **Diagn√≥stico m√©dico:** Mejor detectar a m√°s pacientes enfermos, aunque haya falsos positivos.\n","\n","   - **Sistemas de seguridad:** Mejor marcar posibles amenazas, aunque algunas sean err√≥neas.\n","\n","   - **Reconocimiento facial en aeropuertos:** Detectar terroristas aunque algunos pasajeros inocentes sean revisados.\n","\n","- No se usa si los falsos positivos dan problema en el contexto.\n","\n","   - **Detecci√≥n de fraude:** No se puede marcar muchas transacciones leg√≠timas como fraude.\n","\n","   - **Clasificaci√≥n de correos spam:** No queremos que correos importantes terminen en spam.\n","\n","<FONT SIZE=5 COLOR=\"blue\"> 3. Precision (Precisi√≥n) </FONT>\n","\n","- Es la proporci√≥n de verdaderos positivos dividido entre los resultados etiquetados como positivos.\n","\n","- Indica qu√© tan confiables son las predicciones positivas de un modelo de clasificaci√≥n. Muy √∫til cuando los Falsos Positivos (FP) son costosos y se quiere evitar predicciones incorrectas de la clase positiva.\n","\n","$$Precision = \\dfrac{VP}{VP+FP}$$\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/Imagen/confusi√≥n_ej2.PNG?raw=true\" alt=\"centered image\" width=\"600\" height=\"400\"></center>\n","<br>\n","\n","- Esta m√©trica no funciona bien si los datos est√°n desbalanceados.\n","\n","- No es √∫til si los falsos negativos (FN) son m√°s graves que los falsos positivos. Por ejemplo, en detecci√≥n de terremotos, es preferible dar muchas alertas (FP) antes que ignorar un sismo real (FN).\n","\n","<FONT SIZE=5 COLOR=\"blue\"> 4. Especifity (Especificidad) </FONT>\n","\n","- Es la proporci√≥n de casos negativos que fueron correctamente identificadas por el algoritmo. Es decir, es la tasa de  Verdaderos Negativos.\n","\n","$$Especifity = \\dfrac{VN}{VN+FP}$$\n","\n","*En el area de la salud se dice que la especificidad es la capacidad de poder identificar los casos de pacientes sanos entre todos los sanos*\n","\n","- **Ventajas de la Especificidad**\n","\n","   - Minimiza los falsos positivos (FP). Es clave cuando un falso positivo tiene consecuencias graves, como una sanci√≥n injusta. Por ejemplo, en la detecci√≥n de terrorismo, se queremos marcar inocentes como sospechosos.\n","   - Ideal en sistemas donde una decisi√≥n err√≥nea tiene altos costo Por ejemplo: en juicios legales, es preferible evitar condenar a inocentes (baja FP), aunque algunos culpables escapen.\n","\n","- **Desventajas de la Especificidad**\n","\n","  - No considera los falsos negativos (FN). Un modelo con alta especificidad puede fallar en detectar muchos casos positivos. Por ejemplo: Si un test de c√°ncer prioriza especificidad sobre sensibilidad, muchos pacientes enfermos podr√≠an quedar sin diagn√≥stico.\n","\n","  - No es √∫til en detecci√≥n temprana de enfermedades o fraudes. En casos donde es cr√≠tico detectar todos los positivos, la especificidad puede ser menos importante que el recall. Ejemplo: En detecci√≥n de fraude bancario, preferimos marcar algunos falsos positivos que perder fraudes reales.\n","  \n","  - No funciona bien si la clase negativa es mucho m√°s frecuente. En un dataset desbalanceado, la especificidad puede parecer alta simplemente porque hay muchos negativos.\n","\n","<FONT SIZE=5 COLOR=\"blue\"> 5. F1-Score </FONT>\n","\n","- Esta una m√©trica muy empleada porque nos resume la precisi√≥n y sensibilidad en una sola m√©trica, es decir, combina a precision con recall. Por ello es de gran utilidad cuando la distribuci√≥n de las clases es desigual, por ejemplo cuando el n√∫mero de pacientes con una condici√≥n es del 15% y el otro es 85%.\n","\n","- Es la media arm√≥nica de precision y recall. Esto implica que penaliza valores muy dispares entre estas m√©tricas\n","\n","$$F1 = \\dfrac{2*precision*recall}{precision+recall} $$\n","\n","$$ F1= \\dfrac{2}{ \\dfrac{1}{precision}+\\dfrac{1}{recall}} $$\n","\n","- **Ventajas del F1-Score**\n","\n","   - Equilibra precisi√≥n y recall. Es √∫til cuando una m√©trica es mucho m√°s alta que la otra. Evita que un modelo con alta precisi√≥n y bajo recall o alto recall y baja precisi√≥n tenga una puntuaci√≥n enga√±osa.\n","\n","   - Funciona bien en datos desbalanceados. Accuracy no es √∫til en datasets desbalanceados, pero F1-score s√≠.\n","\n","   - F√°cil de interpretar y comparar entre modelos.\n","\n","Si un modelo tiene mejor F1-score que otro, en general es superior.\n","\n","- **Desventajas del F1-Score**\n","\n","   - No diferencia entre falsos positivos y falsos negativos. En algunos casos, los FN son m√°s costosos que los FP (ej. detecci√≥n de c√°ncer). En otros casos, los FP son m√°s costosos que los FN (ej. detecci√≥n de fraude bancario).\n","\n","   - No considera la especificidad.  No mide qu√© tan bien el modelo predice los negativos correctamente.\n","\n","   - Puede ser enga√±oso en ciertos casos. Si los costos de FP y FN son muy diferentes, es mejor analizar precisi√≥n y recall por separado.\n","\n","\n","***Algunas observaciones (resumen)***:\n","\n","**Alta precisi√≥n y alto recall**: el modelo de Machine Learning escogido maneja perfectamente esa clase.\n","\n","**Alta precisi√≥n y bajo recall**: el modelo de Machine Learning escogido no detecta la clase muy bien, pero cuando lo hace es altamente confiable.\n","\n","**Baja precisi√≥n y alto recall**: El modelo de Machine Learning escogido detecta bien la clase,  pero tambi√©n incluye muestras de la otra clase.\n","\n","**Baja precisi√≥n y bajo recall**: El modelo de Machine Learning escogido no logra clasificar la clase correctamente.\n","\n","- Cuando se tiene un conjunto de datos con clases **desbalanceadas**, suele ocurrir que obtenemos un alto valor de precisi√≥n en la clase mayoritaria y un bajo recall en la clase minoritaria.  En el campo de la salud esta circunstancia es particularmente frecuente y se debe recurrir al balanceo de clases.\n","\n","- La precisi√≥n es un gran estad√≠stico, pero es √∫til √∫nicamente cuando se tienen conjuntos de datos sim√©tricos (la cantidad de casos de la clase 1 y de las clase 2 tienen magnitudes similares)\n","\n","- El indicador F1 de la matriz de confusi√≥n es √∫til si se tiene una distribuci√≥n de clases desigual.\n","\n","- Elija mayor precisi√≥n para conocer qu√© tan seguro est√° de los verdaderos positivos, Mientras que la sensibilidad o ‚ÄúRecall‚Äù le servir√° para saber si no est√° perdiendo positivos.\n","\n","- Las Falsas Alarmas:  Por ejemplo,  si cree que es mejor en su caso tener falsos positivos que falsos negativos, utilice una sensibilidad alta  (Recall) , cuando la aparici√≥n de falsos negativos le resulta inaceptable pero no le importa tener falsos positivos adicionales (falsas alarmas). Un ejemplo de esto es:  Prefieres que algunas personas sanas sean etiquetadas como diab√©ticas en lugar de dejar a una persona diab√©tica etiquetada como sana.\n","\n","- Elija precisi√≥n (precision en ingl√©s)  si quiere estar m√°s seguro de sus verdaderos positivos. por ejemplo, correos electr√≥nicos no deseados.  En este caso se prefiere tener algunos correos electr√≥nicos ‚Äúno deseados‚Äù en su bandeja de entrada en lugar de tener correos electr√≥nicos ‚Äúreales‚Äù en su bandeja de SPAM.\n","\n","- Elija alta Especificidad si desea identificar los verdaderos negativos, o lo que es igual cuando no desea falsos positivos. Por ejemplo conductores y las pruebas de alcoholemia\n","\n","Referencia : https://www.juanbarrios.com/la-matriz-de-confusion-y-sus-metricas/\n","\n"],"metadata":{"id":"z68RGh9Zag1l"}},{"cell_type":"markdown","metadata":{"id":"zxREriCb9iH5"},"source":["Con base a lo anterior vamos a construir la matriz de confusi√≥n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h6a-VWvC1KwN"},"outputs":[],"source":["# construcci√≥n de la matriz de confusi√≥n\n","from sklearn import metrics\n","metrics.confusion_matrix(y_test, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"wq2cPiiYtaRu"},"source":["Una versi√≥n m√°s elaborada de la matriz de confusi√≥n."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LWYlILDN6llf"},"outputs":[],"source":["MC= metrics.confusion_matrix(y_test, y_pred)\n","p = sns.heatmap(pd.DataFrame(MC),                    # data.frame\n","                annot=True,                          # colocar n√∫meros de las cajitas\n","                annot_kws = {'size':20},             # tama√±o de la letra\n","                cmap=\"YlOrRd\",                       # color de la letra 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu'\n","                fmt='g')                             # para que salgan los n√∫mero no : notaci√≥n cient√≠fica\n","plt.title('Matriz de Confusi√≥n en test', y=1.1)\n","plt.ylabel('Valores Reales')\n","plt.xlabel('Predicciones')"]},{"cell_type":"markdown","metadata":{"id":"Nx2INYvf96ks"},"source":["Vamos a calcular las m√©tricas mencionadas anteriormente:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dwJFuSFY91bT"},"outputs":[],"source":["#accuracy score\n","# nombre de las m√©tricas\n","metrics=[\"accuracy\", \"recall\" , \"specificidad\", \"precision\", \"f1\"]\n","# valores\n","values = [accuracy_score(y_test,y_pred),\n","          recall_score(y_test,y_pred),\n","          specificity_score(y_test,y_pred),\n","          precision_score(y_test,y_pred),\n","          f1_score(y_test,y_pred)]\n","pd.DataFrame({\"metrics\": metrics , \"values\" : values})"]},{"cell_type":"markdown","source":["| M√©trica   | ¬øPor qu√© es importante en detecci√≥n de diabetes? |\n","|---------- |---------|\n","| Recall       | Es clave porque queremos detectar todos los pacientes con diabetes y minimizar los falsos negativos (FN). <br> Un FN significar√≠a que un paciente enfermo no recibe tratamiento a tiempo.  |\n","| F1-Score    | Si hay un desbalance en los datos (pocos casos positivos), ayuda a equilibrar precisi√≥n y recall.<br> Evita que un modelo con alta precisi√≥n pero bajo recall o viceversa sea enga√±oso.   |\n","| Precision    | Es importante, pero no tan prioritaria como el recall. <br>Un alto recall puede generar algunos falsos positivos (FP), pero es preferible hacer m√°s pruebas a pacientes <br> falsamente etiquetados con diabetes que dejar enfermos sin diagn√≥stico.   |\n","| Especificidad    | Puede ser √∫til, pero no es la m√©trica principal. <br>Si la especificidad es demasiado alta, podr√≠a significar que el modelo no detecta suficientes casos de diabetes.   |"],"metadata":{"id":"XsR2nxt-WlOS"}},{"cell_type":"markdown","metadata":{"id":"xhci7d2O-AbN"},"source":["Otra forma de revisar las m√©tricas es con el *classification_report*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9QlAzMIg-DWS"},"outputs":[],"source":["print(classification_report(y_test,y_pred))"]},{"cell_type":"markdown","metadata":{"id":"-ehqc7RMAEE2"},"source":["**Conclusiones**:\n","\n","- El modelo est√° clasificando bien al $73\\%$ de los registros. No es un valor muy alto.\n","\n","- El *recall* es $0.47$, es decir, de las personas que tienen diabetes, el algoritmo detecta correctamente un $45\\%$. El algoritmo no es tan bueno detectando personas con diabetes en los que s√≠ tienen la enfermedad.\n","\n","- Se recomienda, tratar de optimizar los hiperpar√°metros o utilizar otro modelo."]},{"cell_type":"markdown","metadata":{"id":"FAzMR4_0-zDH"},"source":["# <FONT SIZE=5 COLOR=\"Purple\"> 6. Predicci√≥n en KNN </FONT>\n","\n"]},{"cell_type":"markdown","source":["Aunque el rendimiento del modelo no es el mejor, vamos a mostrar como se har√≠a una predicci√≥n de un valor nuevo."],"metadata":{"id":"0qBH0xIr-uqP"}},{"cell_type":"markdown","metadata":{"id":"1yvrS3bbM8ph"},"source":["Particularmente, en estos algoritmos en los que se debe escalar, se deben escalar los valores a predecir. Este escalamiento se hace con base a $X_{train}$.\n","\n","Supongamos que queremos predecir si una paciente es propensa a tener diabetes o no, con los siguientes valores:\n","\n","- ***Pregnancies*** : 6\n","- ***Glucose*** : 148\n","- ***BloodPressure*** : 72\n","- ***SkinThikness*** : 35\n","- ***Insulin*** : 80\n","- ***BMI*** : 33.6\n","- ***DiabetesPedigreeFunction*** : 0.627\n","- ***Age*** : 50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wl4Owkwbt0S3"},"outputs":[],"source":["# representamos en forma de lista\n","[6,\t148,\t72,\t35,\t80,\t33.6,\t0.627, 50]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fxIS-_HLL8WG"},"outputs":[],"source":["# usamos la funci√≥n escalar.transform\n","X_new = np.array([[6,\t148,\t72,\t35,\t80,\t33.6,\t0.627,\t50]])\n","X_test1 = escalar.transform(X_new)\n","X_test1"]},{"cell_type":"code","source":["KNN.predict(X_test1)"],"metadata":{"id":"zQq2Mrd7w4Aa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora bien, podemos ver los vecinos m√°s cercanos a este valor"],"metadata":{"id":"HjXjjoyMw_2V"}},{"cell_type":"code","source":["from sklearn.neighbors import NearestNeighbors\n","# ver los vecinos m√°s cercanos\n","distancias, indices = KNN.kneighbors(X_test1,\n","                                     n_neighbors=10,\n","                                     return_distance=True)"],"metadata":{"id":"WgIxaZqsxFrv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vecinos_cercanos = X_train.iloc[indices[0]]\n","vecinos_cercanos[\"distancias\"] = distancias[0]\n","vecinos_cercanos[\"resultados_vecinos\"] = y_train.iloc[indices[0]]\n","vecinos_cercanos"],"metadata":{"id":"R7o4edutB7EB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EsJ8N4Xju6UW"},"source":["# <FONT SIZE=5 COLOR=\"purple\"> 7. Validaci√≥n Cruzada </FONT>\n","\n","La **validaci√≥n cruzada**, o *cross validation*, es una t√©cnica utilizada para evaluar los resultados obtenidos de un modelo de *machine learning* y garantizar que son independientes de los conjuntos de entrenamiento ($X_{train}$) y prueba ($X_{test}$).\n","\n","- Cuando usamos la funci√≥n de *sklearn*:\n","\n","$$train\\_test\\_split(X, y, random\\_state = 123 )$$\n","\n","se extraen dos muestras aleatorias como conjuntos de entrenamiento y prueba. Luego se hace el proceso de entrenamiento y validaci√≥n del modelo, teniendo como referencias las muestras seleccionadas. Sin embargo, una pregunta natural es:\n","\n","**¬øQu√© sucede si tomo otras muestras como conjunto de entrenamiento y de prueba, obtendr√© los mismos resultados?**\n","\n","Para responder lo anterior, debemos seleccionar varias muestras que correspondan a conjunto de entrenamiento y prueba diferentes y hacer el an√°lisis del modelo. Precisamente, esto es lo que hace el proceso de validaci√≥n cruzada.\n","\n","Se divide el conjunto de datos en $n$ partes, de las cuales se toma una como conjunto de *prueba* y las otras $n-1$ como conjunto de entrenamiento. Y vamos rotando el conjunto de prueba, tal y como se muestra en la siguiente figura.\n","\n","<br>\n","\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/val_cruzada/validation1.png?raw=true?\" alt=\"centered image\" width=\"600\" height=\"350\"></center>\n","\n","<br>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H-KzaKC8uzNV"},"outputs":[],"source":["# Validaci√≥n cruzada k fold\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.pipeline        import make_pipeline\n","\n","pipeline = make_pipeline(StandardScaler(), KNN)\n","\n","#kfold_validacion = KFold(10)                              # divide los datos en 10 pliegues.\n","resultados = cross_val_score(pipeline,                     # modelo aplicado\n","                             X,                            # conjunto de predictores\n","                             y,                            # variable de respuesta\n","                             cv = 10,                       # n√∫mero de divisiones en cross-validation.\n","                             scoring = \"accuracy\")         # se puede escoger la m√©trica.\n","print(resultados)                                          # para ver la variable resultados.\n","resultados.mean()"]},{"cell_type":"markdown","source":["Obtenemos en promedio 0.74 de *Accuracy*"],"metadata":{"id":"AqSX7kd518Ha"}},{"cell_type":"markdown","source":["# <FONT SIZE=5 COLOR=\"purple\"> 8. Par√°metro vs Hiperpar√°metro </FONT>\n","\n","Iniciaremos definiendo los siguientes conceptos:\n","\n","**Par√°metros**:\n","\n","- Son variables propias del modelo y que se obtienen de forma autom√°tica usando el conjunto de entrenamiento. Es decir, se estiman a partir de los datos.  \n","\n","- Por ejemplo, en regresi√≥n lineal buscamos una ecuaci√≥n de la forma $y= \\beta_1 x +\\beta_0$ y precisamente este tipo de modelo nos ayuda a encontrar estos valores de $\\beta_1$ y $\\beta_0$.\n","\n","***Hiperpar√°metros:***\n","\n","- Son par√°metros de aprendizaje autom√°tico que se eligen antes de iniciar el proceso de aprendizaje autom√°tico.\n","\n","- Son variables externas al modelo que no se obtienen autom√°ticamente a partir de los datos.\n","\n","- Son ajustables y pueden afectar directamente a la forma en la que se entrena un modelo de aprendizaje autom√°tico.\n","\n","Algunos de estos hiperpar√°metros son:\n","\n","- *N√∫mero de vecinos en knn*\n","\n","- *N√∫mero de √©pocas en redes neuronales*\n","\n","- *N√∫mero de ramas en un √°rbol de decisi√≥n*\n","\n","- *N√∫mero de cl√∫steres en un algoritmo de agrupamiento*\n","\n","- *Tipo de kernel en SVM*\n","\n","Los hiperpar√°metros son flexibles, ya que se refieren a cualquier elemento en el machine learning y el deep learning que decida sus valores o elija su configuraci√≥n antes de que comience el entrenamiento y cuyos valores permanecen iguales cuando se finaliza el entrenamiento.\n","\n","Los par√°metros, por su lado, son caracter√≠sticas inherentes al modelo. Esto quiere decir que se aprenden o se estiman a partir de los datos brindados durante el entrenamiento, ya que el algoritmo que se use intentar√° aprender a partir de las caracter√≠sticas de entrada y la variable objetivo.\n","\n","**Hiperpar√°metros de KNN**\n","\n","Particularmente en el algoritmo de ***knn***, k-vecinos m√°s cercanos tenemos los siguientes hiperp√°metros.\n","\n","- El ***n√∫mero de vecinos*** $k$.\n","\n","- Las ***m√©tricas***. Las m√°s cl√°sicas se pueden seleccionar entre:\n","\n","   - Euclideana\n","   - Manhattan\n","   - Minkowski\n","\n","- Los ***pesos*** en las m√©tricas.\n","\n","   - Uniformes\n","   - Respecto a la distancia.  \n","\n","Podemos ver la documentaci√≥n para ampliar la informaci√≥n\n","\n","[ALGORITMO KNN-sklearn üåé](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n"],"metadata":{"id":"FBMrMB6wZkEb"}},{"cell_type":"markdown","metadata":{"id":"LjQ39YTuvG6w"},"source":["# <FONT SIZE=5 COLOR=\"purple\"> 9. B√∫squeda en Grilla </FONT>\n","\n","- La ***b√∫squeda en grilla*** (grid search) es un m√©todo que busca las mejores combinaciones de hiperpar√°metros que hacen que un modelo tenga el error m√°s bajo, es decir, estimaciones m√°s precisas.\n","\n","- En cada combinaci√≥n de hiperpar√°metros, la b√∫squeda en grilla aplica el proceso de *cross-validation* con el fin de dar una mejor evaluaci√≥n del modelo en cada punto.\n","\n","- Cuando hablamos de b√∫squeda en grilla tenemos algunas alternativas: Grid Search y Random Grid Search. La primera se denomina propiamente *Grid Search* y en este m√©todo, se toman todas las combinaciones posibles de los hiperpar√°metros que se van a revisar. Como se ilustra en la siguiente gr√°fica.\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/val_cruzada/grid1.png?raw=true?\" alt=\"centered image\" width=\"600\" height=\"350\"></center>\n","<br>"]},{"cell_type":"markdown","source":["- Por otro lado, tenemos el ***Random Search***, que es una versi√≥n del primero donde no se toman todas las combinaciones de hiperpar√°metros sino que se selecciona una determinada cantidad aleatoria de combinaciones. Este m√©todo es √∫til cuando se tienen muchos hiperpar√°metros y el procesamiento puede demorarse.\n","\n","<br>\n","<center><img src=\"https://github.com/Fabian830348/cursos/blob/master/val_cruzada/grid2.png?raw=true?\" alt=\"centered image\" width=\"600\" height=\"400\"></center>"],"metadata":{"id":"7o07dgnqbLSu"}},{"cell_type":"markdown","source":["Para hacer la b√∫squeda en grilla, vamos a considerar los siguientes par√°metros\n","\n","1. El n√∫mero de vecinos $k$ : [1,20]\n","2. Las m√©tricas : *euclideana* y *manhattan*\n","3. Los pesos: \"uniformes\" o basados en \"distancia\"\n","\n","De acuerdo con lo anterior tenemos\n","\n","$$(20 \\, vecinos) \\times ( 2 \\, metricas) \\times ( 2 \\, pesos) = 80$$\n","\n","combinaciones de par√°metros."],"metadata":{"id":"OFU9XmRsbiY2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OGSluflxvR2v"},"outputs":[],"source":["from sklearn.pipeline import Pipeline\n","\n","# Crear pipeline con escalador y modelo\n","pipe = Pipeline([\n","    (\"scaler\", StandardScaler()),\n","    (\"knn\", KNeighborsClassifier())\n","])\n","\n","# definimos los par√°metros que vamos a combinar. Diccionario\n","grid_params = {\"knn__n_neighbors\" : list(range(1, 21)),         # se recorre la lista en k\n","               \"knn__weights\" : [\"uniform\",\"distance\"],         # se establecen los pesos\n","               \"knn__metric\" : [\"euclidean\",\"manhattan\"]}       # se establecen las m√©tricas\n","\n","# hacemos la b√∫squeda en grilla con 5-folds\n","Grid_Search = GridSearchCV(pipe,                                     # el modelo aplicado\n","                           grid_params,                             # los par√°metros que van a variar\n","                           cv = 10,                                 # el n√∫mero de folds\n","                           verbose = 3)                             # para que imprima resultados. Posibilidades: 1,2 o 3\n","# Entrenar el modelo obtenido arriba\n","g_res = Grid_Search.fit(X_train,y_train)"]},{"cell_type":"markdown","metadata":{"id":"Fz22advXvpOQ"},"source":["Ahora, buscamos el mejor *score*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nx9iLativXJf"},"outputs":[],"source":["print(\"Mejor score: \",g_res.best_score_)"]},{"cell_type":"markdown","metadata":{"id":"NByeZ0aSvp2Q"},"source":["Finalmente, los hiperpar√°metros que lograron ese *score*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PDROtYIzvaZK"},"outputs":[],"source":["print(\"Mejores hiperpar√°metros\", g_res.best_params_)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1x_sHZ2G9k-VgzO35fOyjdECgPGZW5Cqk","timestamp":1692975942100}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}